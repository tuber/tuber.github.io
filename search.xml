<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[TCP除了3次握手四次挥手之外的基础知识]]></title>
    <url>%2F2019%2F11%2F04%2Ftcp-not-only-3handshank-4byebye%2F</url>
    <content type="text"><![CDATA[tcp特点 使用tcp双方的链接分配必要的内核资源，以管理连接的状态和连接上的数据的传输。全双工，即双方的数据读写可以通过一个连接进行。完成数据交换后，需要断开连接以释放系统资源。因为是一对一，所以基于广播和多播的协议不能使用tcp程序。tcp模块发送数据时，涉及到发送缓冲区可能被封装成一个或者多个tcp报文段发出。由此可见，tcp模块发送出的tcp报文段的个数和应用程序执行写的操作次数之间没有固定的数量的关系。 当接收端收到一个或者多个tcp报文段后，tcp模块将他们携带的应用的程序数据按照tcp报文段的序号依次放入到tcp接收缓冲区中。并通知应用程序去读取数据，接收端应用程序可以一次性将tcp接受缓冲区的数据全部取出，也可以分多次读取。这个取决于用户指定的应用程序缓冲区的大小。由此可见，应用程序执行的读操作次数和tcp模块接收到tcp报文段个数之间也没有固定的数量关系。 字节流的概念：发送端执行的写操作次数和接收端执行的读操作次数之间没有任何的数量关系，这就是字节流的概念。应用程序对数据的发送和接收是没有唯一边界限制的。而udp发送端应用程序每执行一次写，udp模块就将其封装成一个udp数据报并发送，接收端必须及时接收每个udp数据报进行读操作（recvfrom），否则就会丢包。此外，如果用户没有指定足够的应用程序缓冲区来读取udp数据，则udp数据将被截断。 一些机制 定时器 未收到回应后重发（定时器） RWND:receiver window：接收通告窗口 tcp对ip数据报进行重排，整理，再交付给上层 tcp头部结构 16位源端口|目的端口号，一般客户端选择临时，而服务端采取固定/etc/services 32位序列号 sequence number：一次tcp通信（从tcp连接到断开过程中某个一个传输方向上的某一个传输方向上的字节流的每个字节的每个子节点编号） tcp四次关闭流程（假设客户端首先发起关闭） 客户端主动关闭，发送fin报文，客户端进入FIN_WAIT1 服务端收到客户端关闭连接后，会发送一个ack状态。进入CLOSE_WAIT状态,而此时客户端会进入FIN_WAIT2状态（此时wait2等待的是服务端发送的fin）。CLOSE_WAIT状态意思是等待服务器应用程序关闭连接，如果没有服务器没有阻塞，也会给客户端发送一个fin结束报文，然后服务端会进入到LAST_ACK状态，等待客户端对刚刚服务器发送的fin的最后的确认。如果服务器一直阻塞在某个程序（比如io阻塞），那么就一直会在close_wait状态。客户端给予最后的服务端的fin之后，会进入TIME_WAIT状态。 如果客户端发送最后一个ack给服务器。那么服务端就会进入close。 四次挥手是因为是全双工，A一方发送fin后，另一B方只能暂且发送ack，因为此方B不明确上层协议是否还有数据要发送给A。A只是说我不发了，B你有数据发给A，A还是可以接受的。 tcp三次握手过程 服务端listen，进入被动调用状态 服务端收到客户端connect调用发送的syn同步报文，服务端将该连接放入到内核等待队列中，此时客户端处于SYC_SENT状态 服务端向客户端发送带syn+ack标志的确认报文段，ack的值为客户端syn的值+1，此时服务端处于SYN_RCVD状态 客户端发送ack，服务端正确接收。双方为ESTABLISHED状态， 三次握手的本质是确认客户端的收发能力和服务端的收发能力完全正常。 半关闭状态指的是 客户端处于FIN_WAIT2 服务端处于CLOSE_WAIT连接处在fin_wait2的状态情况可能发生在，客户端执行半关闭后，未等服务器关闭连接后就强行退出。此时客户端连接会由内核来接管。可称为孤儿连接。linux为了防止孤儿连接长时间再内核中，定义如下两个变量控制max数量及孤儿连接时间 root@udev:/home/tb/tbtmp# cat /proc/sys/net/ipv4/tcp_max_orphans # orphans 是孤儿的意思 4096 root@udev:/home/tb/tbtmp# cat /proc/sys/net/ipv4/tcp_fin_timeout 60 如何模拟半连接？ 半连接状态下，如果对端发送数据，对方将回应一个复位报文段。客户端可以通过拔掉网线，服务端可以通过停止服务。 TIME_WAIT状态存在的原因有以下两点 可靠的终止tcp连接 为了保证客户端最后发送的ack如果中途丢失了，那么服务端会再次发送fin+ack，客户端需要在当前状态下再次回复当前连接的最后一个ack。否则会导致1. 客户端发送rst回应服务器，2.服务器莫名其妙（你不该给我ack吗） 保证让迟来的tcp报文段有足够的时间被识别并丢弃 tcp端口在处于time_wait状态不能同时打开两次（可以用nc工具测试，断开并且马上用重复端口连接服务器）。如果断开连接后，客户端没有这个状态，则这个新连接可能收到和之前连接相同的tcp报文段（迟到的报文段） tcp 2msl的概念 一个新的tcp连接应该在2msl之后安全建立。但是客户端本身由于临时端口的随机性，理论上可以关闭而无需time_wait（SO_REUSEADDR选项可以控制）状态。而考虑到服务端的固定端口就不大能接受了。 复位报文段 访问不存在的端口,可以看到服务端复位报文段窗口大小win=0，seq=0，length=0.说明客户端也无法回复这个复位报文段。 12345root@php56:/home/tb# tcpdump -nt -i enp0s3 port 33765tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytesIP 10.70.30.73.43936 &gt; 10.70.30.60.33765: Flags [S], seq 577022539, win 29200, options [mss 1460,sackOK,TS val 22768358 ecr 0,nop,wscale 7], length 0IP 10.70.30.60.33765 &gt; 10.70.30.73.43936: Flags [R.], seq 0, ack 577022540, win 0, length 0 异常终止连接（socket选项SO_LINGER来发送） 一旦发送了一个复位报文段，发送端所有排队等待的数据都会被丢弃 这种不会进入到time_wait阶段，所以随之而来的问题可想而知（根据time_wait状态存在的意义） tcp的交互数据和成块数据 交互数据可以理解为命令行下的交互 比如telnet，ssh。而成块数据涉及ftp等。以下为本机抓包23端口（登陆后输入ls的抓包细节） 1234567891011121314151617tb@php56:~$ ls...1.IP 127.0.0.1.50188 &gt; 127.0.0.1.23: Flags [P.], seq 93:94, ack 503, win 350, options [nop,nop,TS val 21041646 ecr 21040271], length 12.IP 127.0.0.1.23 &gt; 127.0.0.1.50188: Flags [P.], seq 503:504, ack 94, win 342, options [nop,nop,TS val 21041646 ecr 21041646], length 13.IP 127.0.0.1.50188 &gt; 127.0.0.1.23: Flags [.], ack 504, win 350, options [nop,nop,TS val 21041646 ecr 21041646], length 04.IP 127.0.0.1.50188 &gt; 127.0.0.1.23: Flags [P.], seq 94:95, ack 504, win 350, options [nop,nop,TS val 21042291 ecr 21041646], length 15.IP 127.0.0.1.23 &gt; 127.0.0.1.50188: Flags [P.], seq 504:505, ack 95, win 342, options [nop,nop,TS val 21042291 ecr 21042291], length 16.IP 127.0.0.1.50188 &gt; 127.0.0.1.23: Flags [.], ack 505, win 350, options [nop,nop,TS val 21042291 ecr 21042291], length 0...# ls回车敲下之后tb@php56:~$ lsanyconnect-linux64-4.6.03049 data_mei draveness.me mount_all tmptest zikao_codinganyconnect-linux64-4.6.03049-predeploy-k9.tar.gz dev_xin_tmp login_lixinghang.sh tb_down vboxguestadition7.IP 127.0.0.1.50188 &gt; 127.0.0.1.23: Flags [P.], seq 95:97, ack 505, win 350, options [nop,nop,TS val 21062968 ecr 21042291], length 28.IP 127.0.0.1.23 &gt; 127.0.0.1.50188: Flags [P.], seq 505:911, ack 97, win 342, options [nop,nop,TS val 21062968 ecr 21062968], length 4069.IP 127.0.0.1.50188 &gt; 127.0.0.1.23: Flags [.], ack 911, win 359, options [nop,nop,TS val 21062968 ecr 21062968], length 0 其中123分半是客户端发送l，服务端对l确认，客户端对服务端l的确认，456同理为s 下面的7可以看到length为两个字节，应该为回车符和流结束符eof，为0x00 第8个length为406个字节，为具体的ls数据输出，包括文件名及其显示控制参数，第9个是客户端对第8个报文段的确认。 针对以上例子简单总结如下： ack表示的是确认号，表示期待接收的下个序列号。 tcp全双工，一个连接上一个方向的tcp报文段都包括了相反方向上的报文段的ack。 客户端对服务端的确认分组，不带任何应用数据 即length=0 而服务端对客户端的确认数据，比如2,5,8既包含ack，又包括应用程序数据length。服务端的这种方式称为延迟确认，即不马上确认收到的客户端的ack，而是等等看是否本端有数据要给客户端，有的话一起在一个报文段里一并发出。即ack是累积的，一个确认字节号N的ack表示所有直到N的字节（不包括N）已经成功被接收。这样可以减少tcp报文段的数量。还有另外一个好处如果一个ack只接受一个，那么其中一个丢失了，那么后面的都得重传。而延迟确认可能将之前可能的ack的字节都一次都确认了。 引申出nagle算法，主要目的就是减少大量小包的发送。Nagle算法的规则（可参考tcp_output.c文件里tcp_nagle_check函数注释），可以理解为他是针对每个包的最大报文段长度（mss）的停等协议。即只有一个未被ACK的包的包的包的包存在于网络。 如果包长度达到MSS，则允许发送； 如果该包含有FIN，则允许发送； 设置了TCP_NODELAY选项，则允许发送； 未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送； 上述条件都未满足，但发生了超时（一般为200ms），则立即发送。 成块数据vftp模拟1234567891011121314151617181920212223242526272829303132333435## 客户端交互数据tb@php56:~$ ftp 127.0.0.1Connected to 127.0.0.1.220 (vsFTPd 3.0.3)Name (127.0.0.1:tb): tb331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ## 服务监听端抓包明细apt-get install vsftpdroot@php56:/home/tb# tcpdump -nt -i lo port 21tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytesIP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [S], seq 3720077491, win 43690, options [mss 65495,sackOK,TS val 21572543 ecr 0,nop,wscale 7], length 0IP 127.0.0.1.21 &gt; 127.0.0.1.34426: Flags [S.], seq 3214185420, ack 3720077492, win 43690, options [mss 65495,sackOK,TS val 21572543 ecr 21572543,nop,wscale 7], length 0IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [.], ack 1, win 342, options [nop,nop,TS val 21572543 ecr 21572543], length 0IP 127.0.0.1.21 &gt; 127.0.0.1.34426: Flags [P.], seq 1:21, ack 1, win 342, options [nop,nop,TS val 21572543 ecr 21572543], length 20: FTP: 220 (vsFTPd 3.0.3)IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [.], ack 21, win 342, options [nop,nop,TS val 21572543 ecr 21572543], length 0IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [P.], seq 1:10, ack 21, win 342, options [nop,nop,TS val 21573111 ecr 21572543], length 9: FTP: USER tbIP 127.0.0.1.21 &gt; 127.0.0.1.34426: Flags [.], ack 10, win 342, options [nop,nop,TS val 21573111 ecr 21573111], length 0IP 127.0.0.1.21 &gt; 127.0.0.1.34426: Flags [P.], seq 21:55, ack 10, win 342, options [nop,nop,TS val 21573111 ecr 21573111], length 34: FTP: 331 Please specify the password.IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [.], ack 55, win 342, options [nop,nop,TS val 21573111 ecr 21573111], length 0IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [P.], seq 10:19, ack 55, win 342, options [nop,nop,TS val 21573327 ecr 21573111], length 9: FTP: PASS tbIP 127.0.0.1.21 &gt; 127.0.0.1.34426: Flags [P.], seq 55:78, ack 19, win 342, options [nop,nop,TS val 21573334 ecr 21573327], length 23: FTP: 230 Login successful.IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [.], ack 78, win 342, options [nop,nop,TS val 21573334 ecr 21573334], length 0IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [P.], seq 19:25, ack 78, win 342, options [nop,nop,TS val 21573334 ecr 21573334], length 6: FTP: SYSTIP 127.0.0.1.21 &gt; 127.0.0.1.34426: Flags [P.], seq 78:97, ack 25, win 342, options [nop,nop,TS val 21573334 ecr 21573334], length 19: FTP: 215 UNIX Type: L8IP 127.0.0.1.34426 &gt; 127.0.0.1.21: Flags [.], ack 97, win 342, options [nop,nop,TS val 21573344 ecr 21573334], length 0 带外数据out of band 用于迅速通告对方本端的重要事件，优先级更高 涉及到紧急指针标志和紧急指针所指向的位置 带外缓存只有一个字节 SS_OOBINLINE选项 tcp超时重传12345678910111213141516171819202122232425262728293031323334# 服务端开启服务apt install iperf3root@php56:/home/tb# iperf3 -s-----------------------------------------------------------Server listening on 5201-----------------------------------------------------------## 在客户端执行参数root@udev:/home/tb# telnet 10.70.30.60 5201Trying 10.70.30.60...Connected to 10.70.30.60.Escape character is &apos;^]&apos;.123412## 客户端抓包结果root@udev:/home/tb# tcpdump -n -i enp0s3 port 5201tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytes16:06:59.057034 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [S], seq 654898028, win 29200, options [mss 1460,sackOK,TS val 26731779 ecr 0,nop,wscale 7], length 016:06:59.057257 IP 10.70.30.60.5201 &gt; 10.70.30.73.55102: Flags [S.], seq 2973035393, ack 654898029, win 28960, options [mss 1460,sackOK,TS val 22374774 ecr 26731779,nop,wscale 7], length 016:06:59.057270 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [.], ack 1, win 229, options [nop,nop,TS val 26731779 ecr 22374774], length 016:07:09.416168 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 1:7, ack 1, win 229, options [nop,nop,TS val 26734369 ecr 22374774], length 616:07:09.416390 IP 10.70.30.60.5201 &gt; 10.70.30.73.55102: Flags [.], ack 7, win 227, options [nop,nop,TS val 22377364 ecr 26734369], length 016:07:28.984171 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26739261 ecr 22377364], length 416:07:29.188603 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26739312 ecr 22377364], length 416:07:29.392513 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26739363 ecr 22377364], length 416:07:29.799504 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26739465 ecr 22377364], length 416:07:30.616060 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26739669 ecr 22377364], length 416:07:32.251692 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26740078 ecr 22377364], length 416:07:35.524165 IP 10.70.30.73.55102 &gt; 10.70.30.60.5201: Flags [P.], seq 7:11, ack 1, win 229, options [nop,nop,TS val 26740896 ecr 22377364], length 4 简单解释 第一段为三次握手 第二段为1234+回车+eof以及服务端的确认 第三段为12+回车+eof的七次重传 相关内核参数 root@udev:/proc/sys/net/ipv4# cat tcp_retries1 3 root@udev:/proc/sys/net/ipv4# cat tcp_retries2 15 拥塞控制 四个部分 慢启动 slow start 拥塞避免 congestion avoidance 快速重传 fast retransmit 快速恢复 fast recovery 涉及算法 reno算法 vegas算法 cubic算法 root@udev:/proc/sys/net/ipv4# cat /proc/sys/net/ipv4/tcp_congestion_control =&gt;cubic 拥塞控制的最终受控变量是发送端向网络一次连续写入（收到其中第一个数据的确认之前）的数据量。称为send window SWND.请注意swnd是限制的tcp报文段的数量，而tcp报文段的最大长度（数据部分）和mss （maximum segment size）有关系。其中这个发送最大长度即称为SMSS.而接收方是通过rwnd（receive window）来告知控制发送端的swnd。值得注意的是，发送端引入了一个称为拥塞窗口 congestion window的状态的变量，实际的cwnd是 min（swnd，rwnd） 慢启动和拥塞避免 tcp建立连接时，cwnd的初始值（initial window），大小一般为2-4个smss，代表发送端最多能发送IW字节的数据。 此后发送端每接收一个确认，cwnd按照以下公式增加：CWND+=MIN(N,SMSS).N代表此次确认中包含的之前的未被确认的字节数，这样CWND将按照指数形式扩大，这就是所谓的慢启动。这个思想是开始发送数据时，并不知道网络的实际情况，需要用一种试探的方式平滑的增加CWND的大小。 慢启动门限 SLOW START THRESHOLD SIZE 缩写为ssthresh ，当cwnd的大小超过该值时，tcp拥塞控制将进入拥塞避免阶段。这样避免了cwnd一直按照线性方式增加，从而避免其扩大。主要通过以下两种方式 每个rtt时间内按照CWND+=MIN(N,SMSS)计算新的cwnd，而不论该rtt时间内发送端接收到多少个确认。 每收到一个对新数据的确认报文段，就按照CWND+=SMSS*SMSS/CWND 发送端判断拥塞发生的依据 传输超时，或者说tcp定时器溢出。应对策略为慢启动和拥塞避免 接收到重复的确认报文段。应对策略为快速重传和快速恢复。 快速重传和快速恢复 发送端如果连续收到3个重复的确认报文段，就认为是拥塞发生了。然后将启用快速重传和快速恢复。按照以下格式：CWND=SSTHRESH+3*SMSS 关于ISN 初始序列号也是绝对序列号，后期的序列号都是这个绝对序列号++。syn消耗序列号，而ack不会消耗。对于发送方和接收方都有自己的ISN的生成规则。ISN,包括对等端的+1操作，都可能涉及到重传操作。 - ISN算法：ISN = M + F(localhost, localport, remotehost, remoteport)，m代表计时器，每隔4微秒+1；F是一个hash算法 - 代码回绕问题 将无符号转为有符号。 关于SYN FOLLD攻击 基本思想：恶意像某个服务器端口发送大量SYN包，服务器会分配一个transmission control block，并返回ack。然后服务端转为syn-recv状态。系统保持这个资源 常见防攻击方法 入门级:系统监视半连开连接和不活动的连接。一视同仁，超过一个阈值后全部rst这些连接。 延缓tcp分配：当三次握手后再分配tcb，这样可以有效的减轻对服务器资源消耗（常见方法是使用syn cache，syn cookie） syn cache 保存对应的序列号和报文（这里特指半连接）到hash表中，直到收到正确的ack报文再分配tcp syn cookie 使用特殊算法生成sequence number，主要涉及到对方无法了解到的己方固定的一些信息（比如己方mss 时间等）。这样如果对方真的发送过来了ack报文，对其ack-1.如果相等，那么就分配这个tcb。没有或者不相等，那就不分配。 syn proxy防火墙：我简单理解为是一层代理，中间有验证，或者涉及到序列号的修改。具体的不了解。。 syn quene and accept quene 如果这两个队列满了，就会丢包。具体怎么个丢法。。不尽相同 syns quene 半连接队列，这时候服务端处理syn_rcvd 状态 linux 默认会进行指数退避算法，重发syn+ack。这也是给syn攻击者的一个机会。1+2+4+8+16+32=63s，tcp才会把这个连接断开。 tcp_syncookies:将连接信息编码在isn中返回给客户端。这时server不需要将半连接报错在队列中，而是利用客户端随后发来的ack带回的isn还原连接信息 tcp_max_syn_backlog tcp_abort_on_overflow：0表示直接丢弃该ACK，1表示发送RST通知client，而客户端则分别返回read timeout 和connection reset by peer tcp_syncookies 以上这些参数遇到问题时可以适时调整参数 accept quene 全连接队列，这时候状态为established，但是未被应用程序accept 这张图对具体的发送时机和状态先后顺序非常清晰。值得保存]！！！]]></content>
      <categories>
        <category>NETWORK</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php同步拉去大量数据的一种可控方法]]></title>
    <url>%2F2019%2F07%2F20%2Fphp-pull-control-by-redis%2F</url>
    <content type="text"><![CDATA[场景数据同步只能通过php脚本拉取三方接口来执行。比如我需要每天拉取从jd商城下单的数据到mysql，jd通过已知接口告知我共多少页多少条数据。大概每天60w条，但是问题是jd接口请求频次受限。而用php请求还有个问题就是脚本可能超时或者由于其他原因异常退出。这样会导致数据插入失败，甚至是插入重复。 实现思路 通过接口查询当天总条数（假设在获取过程中数据变化可控） 根据对方接口频次限制需求及自身机器性能，算出每页多少条可以查询（即插入） mysql插入采用n条数据采用batch方式，缩短事务频次及语法解析频次等 分段插入，插入成功后用redis设置offset，防止对方及自身进程异常退出 在程序入口判断offset值，是否需要从断点处开始或者从1开始，或者是已经插入完成。 php简单代码实现（ci框架）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;?php public function get_jd_order() &#123; $is_success = false; $this-&gt;benchmark-&gt;mark(&apos;jd_order_begin&apos;); set_time_limit(0); ini_set(&apos;memory_limit&apos;, &apos;2048M&apos;); //请求第一页获取总数 $data = $this-&gt;_getOrderId(1); $totalPage = ceil($data[&apos;alltotal&apos;] / 100); if ($this-&gt;yredis-&gt;get(self::_REQ_jd_PAGE_COMPLETE) &lt;= 0) &#123; $page = 1; $this-&gt;_log(&quot;初始化，从第一页开始&quot;); &#125; else if ($page = $this-&gt;yredis-&gt;get(self::_REQ_jd_PAGE_INTERRUPT)) &#123; $page = $this-&gt;yredis-&gt;get(self::_REQ_jd_PAGE_INTERRUPT); $this-&gt;_log(&quot;有中断，从第&#123;$page&#125;页再来&quot;); &#125; else if ($this-&gt;yredis-&gt;get(self::_REQ_jd_PAGE_COMPLETE) == $totalPage) &#123; $this-&gt;_log(&quot;&#123;$totalPage&#125; 页,总条数 &#123;$data[&apos;alltotal&apos;]&#125;都处理完毕，无需同步&quot;); exit; &#125; if (!$totalPage) &#123; exit(&apos;total page zero&apos;); &#125; else &#123; $this-&gt;_log(&quot;京东总页数:&#123;$totalPage&#125;，总条数&#123;$data[&apos;alltotal&apos;]&#125;&quot;); &#125; for ($page; $page &lt;= $totalPage; $page++) &#123; //页数循环到20页时 休息2秒// if ($page % 20 == 0) &#123;// sleep(2);// &#125; $data = $this-&gt;_getOrderId($page); $tempOrderIdArr = $data[&apos;data&apos;]; $detailData = $this-&gt;_getOrderDetail($tempOrderIdArr); if (empty($detailData)) &#123; //停两秒再次 $this-&gt;_log(&quot;detail data empty，sleep 2 second ↓&quot;); sleep(2); $detailData = $this-&gt;_getOrderDetail($tempOrderIdArr); if (empty($detailData)) &#123; $this-&gt;_log(&quot;again detail data empty，exit ↓&quot;); $this-&gt;_log(implode(&apos;,&apos;, $tempOrderIdArr)); $this-&gt;yredis-&gt;set(self::_REQ_jd_PAGE_INTERRUPT, $page); $this-&gt;_log(&apos;$detailData为空&apos;); exit(); &#125; &#125; $insert_data = []; foreach ($detailData as $key =&gt; $value) &#123; $insert_data[] = array_merge($value, [ &apos;order_id&apos; =&gt; $key, &apos;from_source&apos; =&gt; &apos;3&apos;, //订单来源: 京东 &apos;data_generate_date&apos; =&gt; date(&apos;Y-m-d&apos;, time()), ]); &#125; echo &quot; &#123;$page&#125;:获取京东订单第&#123;$page&#125;页\r\n&quot;; echo &quot; &#123;$page&#125;:准备插入: &quot; . count($insert_data) . &quot;条&quot; . &quot;\r\n&quot;;// var_dump(array_diff(array_keys($insert_data[&apos;86&apos;]),array_keys($insert_data[&apos;87&apos;])));die; $this-&gt;crm_w-&gt;trans_begin(); $this-&gt;crm_w-&gt;insert_batch($this-&gt;_insert_table, $insert_data); if ($this-&gt;crm_w-&gt;affected_rows() &lt; 0) &#123; echo &quot;插入失败,失败详情↓\r\n&quot;; $is_success = false; &#125; else &#123; echo &quot;插入完成(ci2.0 insert batch 方法100问题): &quot; . $this-&gt;crm_w-&gt;affected_rows() . &quot;\r\n&quot;; &#125; if ($this-&gt;crm_w-&gt;trans_status() === FALSE) &#123; var_dump($this-&gt;crm_w-&gt;last_query()); $this-&gt;_log(&quot;在第&#123;$page&#125;页有错误 &quot;); $this-&gt;yredis-&gt;set(self::_REQ_jd_PAGE_INTERRUPT, $page); $this-&gt;_log(&quot;需要从&#123;$page&#125;页重新开始 &quot;); var_dump($this-&gt;crm_w-&gt;_error_message()); $is_success = false; exit; &#125; else &#123; $this-&gt;crm_w-&gt;trans_complete(); $this-&gt;_log(&quot;第&#123;$page&#125;页 存储Mysql成功&quot;); $this-&gt;yredis-&gt;set(self::_REQ_jd_PAGE_COMPLETE, $page); if ($this-&gt;yredis-&gt;get(self::_REQ_jd_PAGE_COMPLETE) &gt; $this-&gt;yredis-&gt;get(self::_REQ_jd_PAGE_INTERRUPT)) &#123; $this-&gt;yredis-&gt;del(self::_REQ_jd_PAGE_INTERRUPT); &#125; $this-&gt;_log(&quot;第&#123;$page&#125;页 Redis Set成功&quot;); &#125; &#125; $this-&gt;yredis-&gt;set_timeout(self::_REQ_jd_PAGE_COMPLETE, self::_REQ_jd_PAGE_COUNT_TTL); $this-&gt;yredis-&gt;set_timeout(self::_REQ_jd_PAGE_INTERRUPT, self::_REQ_jd_PAGE_COUNT_TTL); $this-&gt;_log(&quot;京东拉取完成,总时长为 &quot; . $this-&gt;benchmark-&gt;elapsed_time(&apos;jd_order_begin&apos;) . &quot;秒&quot;); return $is_success; &#125; 其他问题 需要尽量提升mysql innodb引擎的性能 代码是基于ci_2.0，ci_2.0的insert_battch有个小bug，返回的affect_rows最大是100.. 注意php的内存限制及执行环境]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>REDIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcpdump 工具查看分析arp协议]]></title>
    <url>%2F2019%2F05%2F13%2Ftcpdump-arp%2F</url>
    <content type="text"><![CDATA[环境准备机器1 udev的mac及ip地址123456789root@udev:/home/tb# ifconfigenp0s3 Link encap:Ethernet HWaddr 08:00:27:63:49:66 inet addr:10.70.30.73 Bcast:10.70.31.255 Mask:255.255.254.0 inet6 addr: fe80::a00:27ff:fe63:4966/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1992020 errors:0 dropped:0 overruns:0 frame:0 TX packets:569243 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:235878919 (235.8 MB) TX bytes:149889975 (149.8 MB) 环境准备机器2 php56当前的mac及ip地址及 arp缓存1234567891011121314151617181920212223242526tb@php56:~$ ifconfigdocker0 Link encap:Ethernet HWaddr 02:42:c6:68:73:96 inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)enp0s3 Link encap:Ethernet HWaddr 08:00:27:ce:14:39 inet addr:10.70.30.60 Bcast:10.70.31.255 Mask:255.255.254.0 inet6 addr: fe80::a00:27ff:fece:1439/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1636533 errors:0 dropped:0 overruns:0 frame:0 TX packets:149265 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:219865638 (219.8 MB) TX bytes:123084741 (123.0 MB)root@php56:/home/tb# arp -a? (10.70.30.79) at 08:62:66:4d:f1:09 [ether] on enp0s3? (10.70.30.32) at 64:00:6a:20:ae:c6 [ether] on enp0s3? (10.70.30.47) at 8c:ec:4b:5f:e9:49 [ether] on enp0s3? (10.70.30.73) at 08:00:27:63:49:66 [ether] on enp0s3? (10.70.30.1) at 84:b2:61:8f:98:00 [ether] on enp0s3? (10.70.30.72) at 8c:ec:4b:a1:49:3f [ether] on enp0s3? (10.70.30.40) at 74:ea:c8:e3:17:ab [ether] on enp0s3? (10.70.31.191) at &lt;incomplete&gt; on enp0s3 删除php56上的10.70.30.73的arp缓存12345678root@php56:/home/tb# arp -d 10.70.30.73#抓php56(10.70.30.66 )上 telnet 到10.70.30.73的包root@php56:/home/tb# tcpdump -i enp0s3 -ent &apos;(dst 10.70.30.73 and src 10.70.30.60) or (dst 10.70.30.60 and src 10.70.30.73)&apos;tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytes# -e选项代表开启以太网帧头部信息显示 新开一个窗口在php56上 telnet，失败不要紧，因为在链路层，arp在tcp连接建立前就已经完成，不关心成功与否123root@php56:/home/tb# telnet 10.70.30.73Trying 10.70.30.73...telnet: Unable to connect to remote host: Connection refused 抓包结果1234567891011121314151617root@php56:/home/tb# tcpdump -i enp0s3 -ent &apos;(dst 10.70.30.73 and src 10.70.30.60) or (dst 10.70.30.60 and src 10.70.30.73)&apos;tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytes08:00:27:ce:14:39 &gt; ff:ff:ff:ff:ff:ff, ethertype ARP (0x0806), length 42: Request who-has 10.70.30.73 tell 10.70.30.60, length 2808:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype ARP (0x0806), length 60: Reply 10.70.30.73 is-at 08:00:27:63:49:66, length 4608:00:27:ce:14:39 &gt; 08:00:27:63:49:66, ethertype IPv4 (0x0800), length 74: 10.70.30.60.42366 &gt; 10.70.30.73.23: Flags [S], seq 803077829, win 29200, options [mss 1460,sackOK,TS val 173958745 ecr 0,nop,wscale 7], length 008:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype IPv4 (0x0800), length 60: 10.70.30.73.23 &gt; 10.70.30.60.42366: Flags [R.], seq 0, ack 803077830, win 0, length 008:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype ARP (0x0806), length 60: Request who-has 10.70.30.60 tell 10.70.30.73, length 4608:00:27:ce:14:39 &gt; 08:00:27:63:49:66, ethertype ARP (0x0806), length 42: Reply 10.70.30.60 is-at 08:00:27:ce:14:39, length 2808:00:27:ce:14:39 &gt; 08:00:27:63:49:66, ethertype IPv4 (0x0800), length 74: 10.70.30.60.42368 &gt; 10.70.30.73.23: Flags [S], seq 3070062063, win 29200, options [mss 1460,sackOK,TS val 173961995 ecr 0,nop,wscale 7], length 008:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype IPv4 (0x0800), length 60: 10.70.30.73.23 &gt; 10.70.30.60.42368: Flags [R.], seq 0, ack 3070062064, win 0, length 008:00:27:ce:14:39 &gt; 08:00:27:63:49:66, ethertype IPv4 (0x0800), length 74: 10.70.30.60.52718 &gt; 10.70.30.73.7: Flags [S], seq 4237197441, win 29200, options [mss 1460,sackOK,TS val 173965580 ecr 0,nop,wscale 7], length 008:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype IPv4 (0x0800), length 60: 10.70.30.73.7 &gt; 10.70.30.60.52718: Flags [R.], seq 0, ack 4237197442, win 0, length 008:00:27:ce:14:39 &gt; 08:00:27:63:49:66, ethertype IPv4 (0x0800), length 74: 10.70.30.60.52720 &gt; 10.70.30.73.7: Flags [S], seq 3993979182, win 29200, options [mss 1460,sackOK,TS val 173969570 ecr 0,nop,wscale 7], length 008:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype IPv4 (0x0800), length 60: 10.70.30.73.7 &gt; 10.70.30.60.52720: Flags [R.], seq 0, ack 3993979183, win 0, length 008:00:27:63:49:66 &gt; 08:00:27:ce:14:39, ethertype ARP (0x0806), length 60: Request who-has 10.70.30.60 tell 10.70.30.73, length 4608:00:27:ce:14:39 &gt; 08:00:27:63:49:66, ethertype ARP (0x0806), length 42: Reply 10.70.30.60 is-at 08:00:27:ce:14:39, length 28 包内容简短解释ff:ff:ff:ff:ff:ff 代表lan内广播地址，所有机器都会收到并处理这样的帧。Ox086代表是以太网帧arp类型（注意分用思想）。length 42字节，实际为46，由于tcpdump不关心以太网帧尾部的crc校验字段。最后的length 28|46 字节代表数据长度。request reply为arp请求 应答 固定标识，最后路由器并不响应arp请求。 参考自下图]]></content>
      <categories>
        <category>NETWORK</category>
      </categories>
      <tags>
        <tag>ARP</tag>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDH Hue入门]]></title>
    <url>%2F2019%2F04%2F01%2Ftransfer-hue%2F</url>
    <content type="text"><![CDATA[翻译自 欢迎及介绍 cdh全称是cloudera open source distribution including apache hadoop的全称。 hue登录用户名：cloudera 密码：cloudera 怎么用cdh 如何进行简单的数据挖掘和分析 让你老板给你涨工资~ 某些点会用到cloudera manager，可能）导致有些功能无法正常运行。有些部件也会用到商业版本的许可才能正常使用。 避免以上问题， 可以用express 版本（最少需要8G内存和2核心cpu） 用企业版的试用版，试用版有60天的体验期。（最少需要10G内存和2核心cpu） 入门 提取查询关系数据之后的教程中，我们将通过呈现一个关于DataCo公司的案例。我们的任务就是帮助这公司深入了解并解决一些问题。 剧情1 12王老板：吐沫星子漫天飞的谈谈大数据。。小明：hadoop吧那就。 剧情2123DataCo公司现在难题是：哪种产品消费者最喜欢买。当然一般想到的是查看一下关系数据库中的交易数据表，排序一下就知道了，有这么简单?但是更有效，更深入分析，且适合更大规模的，就要用到cdh平台（hadoop技术栈了）下面这个例子，我们用cdh做，让你感觉常用的关系型数据库那种方法没啥两样。让你用同等的时间下，还能出更多的BI类分析和其他报表， 首先我们需要一个工具（sqoop）把常用的RDBMS关系型数据库中的结构字段扔到HDFS中（当然是肯定保持同样的数据结构。）这样就类似一个从库，在hdfs上查询不会占用其他的查询压力。 我们用一个优化的文件格式化工具avro，或者用empala做到上面这些工作。 sqoop import-all-tables \ -m 1 \ --connect jdbc:mysql://quickstart:3306/retail_db \ --username=retail_dba \ --password=cloudera \ --compression-codec=snappy \ --as-parquetfile \ --warehouse-dir=/user/hive/warehouse \ --hive-import 注意默认都会到default库，如果需要到指定库，需要增加--hive-database=yourdbname \ 上面的sqoop命令做了很多工作，通过mapreduce任务，拉取mysql数据写入到hdfs（应该是用apache 的parquet列存储格式存储，该列式存储支持hive impala pig等多种查询引擎，而且适配多个计算框架，如mapreduce，spark等）。最终以指定（默认）表的方式体现对应mysql中的schema。 parquet是用来再hadoop平台相关的统一的数据格式。与传统的行模式不同，他是以列存储。主要是为了分析一些特殊指定的数据，可以通过变量来分析关系数据。parquet能更优的存储与检索。 现在我们直观的看一下刚刚插入的hive的具体目录 [cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse Found 7 items drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:36 /user/hive/warehouse/categories drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:38 /user/hive/warehouse/customers drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:39 /user/hive/warehouse/departments drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:40 /user/hive/warehouse/order_items drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:41 /user/hive/warehouse/orders drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:42 /user/hive/warehouse/products drwxrwxrwx - cloudera supergroup 0 2018-04-13 01:41 /user/hive/warehouse/xin.db 通过 hadoop fs -ls 可以到指定标识为d的目录内继续查看，比如 [cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/categories Found 3 items drwxr-xr-x - cloudera supergroup 0 2018-04-15 23:28 /user/hive/warehouse/categories/.metadata drwxr-xr-x - cloudera supergroup 0 2018-04-15 23:36 /user/hive/warehouse/categories/.signals -rw-r--r-- 1 cloudera supergroup 1957 2018-04-15 23:36 /user/hive/warehouse/categories/3e30822b-f7e7-4a0c-bde3-e61f3e373a11.parquet 注意：parquet的文件数量指的是sqoop运行时，mappe任务的数量。因为我的是单节点，所以就是一个。我们追进来看一下元数据 [cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/categories/.metadata Found 1 items drwxr-xr-x - cloudera supergroup 0 2018-04-15 23:28 /user/hive/warehouse/categories/.metadata/schemas [cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/categories/.metadata/schemas Found 1 items -rw-r--r-- 1 cloudera supergroup 594 2018-04-15 23:28 /user/hive/warehouse/categories/.metadata/schemas/1.avsc [cloudera@quickstart ~]$ hadoop fs -cat /user/hive/warehouse/categories/.metadata/schemas/1.avsc { &quot;type&quot; : &quot;record&quot;, &quot;name&quot; : &quot;categories&quot;, &quot;doc&quot; : &quot;Sqoop import of categories&quot;, &quot;fields&quot; : [ { &quot;name&quot; : &quot;category_id&quot;, &quot;type&quot; : [ &quot;null&quot;, &quot;int&quot; ], &quot;default&quot; : null, &quot;columnName&quot; : &quot;category_id&quot;, &quot;sqlType&quot; : &quot;4&quot; }, { &quot;name&quot; : &quot;category_department_id&quot;, &quot;type&quot; : [ &quot;null&quot;, &quot;int&quot; ], &quot;default&quot; : null, &quot;columnName&quot; : &quot;category_department_id&quot;, &quot;sqlType&quot; : &quot;4&quot; }, { &quot;name&quot; : &quot;category_name&quot;, &quot;type&quot; : [ &quot;null&quot;, &quot;string&quot; ], &quot;default&quot; : null, &quot;columnName&quot; : &quot;category_name&quot;, &quot;sqlType&quot; : &quot;12&quot; } ], &quot;tableName&quot; : &quot;categories&quot; 当然我们在hue中用 show create table categories来查看，会看到和上面对应的信息 Show CREATE TABLE categories 1 CREATE TABLE `categories`( 2 `category_id` int, 3 `category_department_id` int, 4 `category_name` string) 5 ROW FORMAT SERDE 6 &apos;org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe&apos; 7 STORED AS INPUTFORMAT 8 &apos;org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat&apos; 9 OUTPUTFORMAT 10 &apos;org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat&apos; 11 LOCATION 12 &apos;hdfs://quickstart.cloudera:8020/user/hive/warehouse/categories&apos; 13 TBLPROPERTIES ( 14 &apos;COLUMN_STATS_ACCURATE&apos;=&apos;false&apos;, 15 &apos;avro.schema.url&apos;=&apos;hdfs://quickstart.cloudera:8020/user/hive/warehouse/categories/.metadata/schemas/1.avsc&apos;, 16 &apos;kite.compression.type&apos;=&apos;snappy&apos;, 17 &apos;numFiles&apos;=&apos;0&apos;, 18 &apos;numRows&apos;=&apos;-1&apos;, 19 &apos;rawDataSize&apos;=&apos;-1&apos;, 20 &apos;totalSize&apos;=&apos;0&apos;, 另外我们在hive命令行中可以看到其他关于表的formated信息 hive&gt; describe formatted customers; OK # col_name data_type comment customer_id int customer_fname string customer_lname string customer_email string customer_password string customer_street string customer_city string customer_state string customer_zipcode string # Detailed Table Information Database: default Owner: null CreateTime: Sun Apr 15 23:36:57 PDT 2018 LastAccessTime: UNKNOWN Protect Mode: None Retention: 0 Location: hdfs://quickstart.cloudera:8020/user/hive/warehouse/customers Table Type: MANAGED_TABLE Table Parameters: COLUMN_STATS_ACCURATE false avro.schema.url hdfs://quickstart.cloudera:8020/user/hive/warehouse/customers/.metadata/schemas/1.avsc kite.compression.type snappy numFiles 0 numRows -1 rawDataSize -1 totalSize 0 transient_lastDdlTime 1523860617 Storage Information SerDe Library: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe InputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat OutputFormat: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat Compressed: No Num Buckets: -1 Bucket Columns: [] Sort Columns: [] Time taken: 0.069 seconds, Fetched: 39 row(s) 当然创建表也可以利用外部已经存在的文件导入（CREATE EXTERNAL TABLE）的方式。以外部表导入的方式不会在hive的仓库中查看到（用hive或者impala都能实现）， 比如下面的例子,我们在hive中执行以下操作 CREATE EXTERNAL TABLE tb_test01(id INT,category_id INT, name string,price INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; STORED AS TEXTFILE location &apos;/user/hive/external/tb_external_table01&apos;; LOCATION指的是warehouse的存放路径，不指定就到hive.metastore.warehouse.dir指定的路径下(一般演示我习惯用TERMINATED ,分割)load 数据到刚刚创建的tb_test01表中，准备数据如下 [cloudera@quickstart tongbo]$ cat hadoop_external_test.txt 1,24551,Cleats,17 2,22246,Men&apos;s Footwear,18 3,21035,Women&apos;s Apparel,24 4,19298,Indoor/Outdoor Games,46 5,17325,Fishing,45 6,15540,Water Sports,48 7,13729,Camping &amp; Hiking,43 8,12487,Cardio Equipment,9 9,10984,Shop By Sport,29 10,2029,Electronics LOAD data local inpath &#39;/home/tongbo/hadoop_external_test.txt&#39; into table tb_test01; 这样就实现了数据的导入。内部表和外部表的区别，简单概况如下：Hive 创建内部表时，会将数据移动到数据仓库指向的路径（配置文件中配置）；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数 据会被一起删除，而外部表只删除元数据，不删除数据。 下面主要说明如何用cdh中的hive（impala） web页面来进行查询操作。默认为8888端口，用户名和密码都是cloudera，mysql用户名为root，密码为cloudera 在hive创建及查询等更新过程中，impala不会自动拉取跟新的元数据（metadata）的改变，所以第一件事情是更新metadata的时效，这样我们可以看到所有目前的表 invalidate metadata; show tables; 当然可以通过内置的hdfs看到实际存储的文件记录。现在关系型数据库中的数据已经到了hdfs里面，回过头来看dataco公司的问题。下面的mysql展示了每个商品的总利润，并且取前十条 SELECT count(order_item_quantity) AS count, c.category_name, c.category_id FROM order_items AS oi INNER JOIN products AS p ON p.product_id = oi.order_item_product_id INNER JOIN categories AS c ON p.product_category_id = c.category_id GROUP BY c.category_name ORDER BY count DESC LIMIT 10; +-------+----------------------+-------------+ | count | category_name | category_id | +-------+----------------------+-------------+ | 24551 | Cleats | 17 | | 22246 | Men&apos;s Footwear | 18 | | 21035 | Women&apos;s Apparel | 24 | | 19298 | Indoor/Outdoor Games | 46 | | 17325 | Fishing | 45 | | 15540 | Water Sports | 48 | | 13729 | Camping &amp; Hiking | 43 | | 12487 | Cardio Equipment | 9 | | 10984 | Shop By Sport | 29 | | 3156 | Electronics | 13 | +-------+----------------------+-------------+ 10 rows in set (0.28 sec) mysql&gt; 下面是hive语法 select count(order_item_quantity) as count ,c.category_name,c.category_id from order_items as oi inner join products as p on p.product_id=oi.order_item_product_id inner join categories as c on p.product_category_id=c.category_id group by c.category_name,c.category_id order by count desc limit 10 注意，hive语法中select后面不能有非聚合列，如果必须要有，需要在group by 上加上你要聚合的字段。在上述hive语法中就是加上 group by c.category_name,c.category_id 1 24551 Cleats 17 2 22246 Men&apos;s Footwear 18 3 21035 Women&apos;s Apparel 24 4 19298 Indoor/Outdoor Games 46 5 17325 Fishing 45 6 15540 Water Sports 48 7 13729 Camping &amp; Hiking 43 8 12487 Cardio Equipment 9 9 10984 Shop By Sport 29 10 2029 Electronics 再看下面一个复杂的sql SELECT p.product_id, p.product_name, r.revenue FROM products AS p INNER JOIN ( SELECT oi.order_item_product_id, sum( cast( oi.order_item_subtotal AS FLOAT ) ) AS revenue FROM order_items oi INNER JOIN orders AS o ON oi.order_item_order_id = o.order_id WHERE o.order_status &lt;&gt; &apos;CANCELED&apos; AND o.order_status &lt;&gt; &apos;SUSPECTED_FARUD&apos; GROUP BY order_item_product_id ) AS r ON p.product_id = r.order_item_product_id ORDER BY r.revenue DESC LIMIT 10 (备注：SUSPECTED_FARUD 涉嫌欺诈) 结果如下：（记住这个结果，下面会用到） p.product_id p.product_name r.revenue 1 1004 Field &amp; Stream Sportsman 16 Gun Fire Safe 6795260.4066467285 2 365 Perfect Fitness Perfect Rip Deck 4335357.441116333 3 957 Diamondback Women&apos;s Serene Classic Comfort Bi 4038330.9078979492 4 191 Nike Men&apos;s Free 5.0+ Running Shoe 3586941.2666854858 5 502 Nike Men&apos;s Dri-FIT Victory Golf Polo 3082050 6 1073 Pelican Sunstream 100 Kayak 3033648.3933258057 7 403 Nike Men&apos;s CJ Elite 2 TD Football Cleat 2831052.3296356201 8 1014 O&apos;Brien Men&apos;s Neoprene Life Vest 2830867.1741104126 9 627 Under Armour Girls&apos; Toddler Spine Surge Runni 1242929.2107200623 10 565 adidas Youth Germany Black/Red Away Match Soc 65940 我用impala和hive分别执行上述语句。发现impala比hive快15倍左右。同时证明了我们用sqoop导入的数据结构（这里指metadata），适用于hive和impala两种引擎。hive非常的灵活，是把sql的查询语法转换成mapreduce任务。而impala更适合交互接口分析，我们下面会再次hive在etl中的使用。 总结一下，我们完成了用sqoop把数据导入到hdfs中，然后把他转换为格式化为avro行式存储。（可以在深入了解avro和parquet的区别）经过以上过程，已经可以用hive或者impala查询数据。我们要更多了了解的是hadoop与传统架构相比，有更多的扩展和灵活性。 剧情三 12领导：（无所谓）的说，你只是展示了你的数据，而且你这些数据我也知道。并没有什么卵用（额外的价值）你：也是一脸淡定的无所谓，然后撸起袖子准备干一下。。 练习2把结构化数据和非结构化数据结合起来作为基础运营，你现在有一点疑问：网站内浏览最多的商品就是卖的最多的吗？如果不是，导致原因是什么?hadoop可以存储结构化和半结构化的数据，而不必向关系型数据库那样，增加一个字段将同步所有的数据列。尤其是适用于web log日志这样的文件形式。我们查看一下最原始的访问站点的日志为了演示方便，我们批量导入180000条数据的access log。先在目录下创建一个目录，然后通过hadoop mv命令复制到warehouse下先看一下当前目录 cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse Found 7 items drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:36 /user/hive/warehouse/categories drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:38 /user/hive/warehouse/customers drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:39 /user/hive/warehouse/departments drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:40 /user/hive/warehouse/order_items drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:41 /user/hive/warehouse/orders drwxrwxrwx - cloudera supergroup 0 2018-04-15 23:42 /user/hive/warehouse/products drwxrwxrwx - cloudera supergroup 0 2018-04-13 01:41 /user/hive/warehouse/xin.db [cloudera@quickstart ~]$ [cloudera@quickstart ~]$ sudo -u hdfs hadoop fs -mkdir /user/hive/warehouse/origin_access_logs 看一下准备好的日志文件： [cloudera@quickstart ~]$ cd /opt/examples/log_files/ [cloudera@quickstart log_files]$ ls access.log.2 [cloudera@quickstart log_files]$ du -f access.log.2 du: invalid option -- &apos;f&apos; Try `du --help&apos; for more information. [cloudera@quickstart log_files]$ du -h access.log.2 38M access.log.2 [cloudera@quickstart log_files]$ 执行复制 [cloudera@quickstart log_files]$ sudo -u hdfs hadoop fs -copyFromLocal /opt/examples/log_files/access.log.2 /user/hive/warehouse/origin_access_logs 由于两次拼写错误，把之前的删除。。 [cloudera@quickstart log_files]$ hadoop fs -rm -f /user/hive/warehouse/origin__access_logs Deleted /user/hive/warehouse/origin__access_logs [cloudera@quickstart log_files]$ hadoop fs -rm -f /user/hive/warehouse/original_access_logs Deleted /user/hive/warehouse/original_access_logs [cloudera@quickstart log_files]$ 验证一下上面的操作 [cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/origin_access_logs Found 1 items -rw-r--r-- 1 hdfs supergroup 39593868 2018-04-17 23:41 /user/hive/warehouse/origin_access_logs/access.log.2 [cloudera@quickstart ~]$ 现在我们可以创建一个表，然后用hive或者更腻害的impala来查询。我们需要以下两步： 利用hive强大灵活的serdes ，解析日志，到自定义的hive表中的各个字段中。（通过（反）序列化到自定义的文件字段中） 转移数据到中间表，以便不需要再次（反）序列化数据放入到表中之后，就可以通过cli或者hue查询啦。下面用hue创建表，并且导入。先贴一下单一一行格式，参考regex的写法 144.72.77.159 - - [14/Jun/2014:17:16:22 -0400] &quot;GET /department/fan%20shop/category/fishing/product/Field%20&amp;%20Stream%20Sportsman%2016%20Gun%20Fire%20Safe HTTP/1.1&quot; 200 1206 &quot;-&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:30.0) Gecko/20100101 Firefox/30.0&quot; CREATE external TABLE intermediate_access_logs ( ip string, date string, method string, url string, http_version string, code1 string, code2 string, dash string, user_agent string ) ROW format serde &apos;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&apos; WITH serdeproperties ( &apos;input.regex&apos; = &apos;([^ ]*) - - \\[([^\\]]*)\\] &quot;([^\ ]*) ([^\ ]*) ([^\ ]*)&quot; (\\d*) (\\d*) &quot;([^&quot;]*)&quot; &quot;([^&quot;]*)&quot;&apos;, &apos;output.format.string&apos; = &quot;%1$$s %2$$s %3$$s %4$$s %5$$s %6$$s %7$$s %8$$s %9$$s&quot; ) LOCATION &apos;/user/hive/warehouse/origin_access_logs&apos; 创建完之后可以用上面讲到的命令在hive命令行执行。 describe formatted intermediate_access_logs; serde这个关键词（应该是序列化，或者格式化），一般这样使用：用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive 通过 SerDe 确定表的具体的列的数据 再说location这个关键词EXTERNAL 关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION）上面那句是) LOCATION &#39;/user/hive/warehouse/origin_access_logs&#39; 另外插一句，上面说的内部表和外部表问题。首先建立一个演示外部表的目录（新建一个）hadoop fs -mkdir -p /user/hive_external_table/然后把原始日志放入到这个目录sudo -u hdfs hadoop fs -copyFromLocal /opt/examples/log_files/access.log.2 /user/hive_external_table/验证以上的结果 [cloudera@quickstart ~]$ hadoop fs -ls /user/hive_external_table/ Found 1 items -rw-r--r-- 1 hdfs supergroup 39593868 2018-04-18 04:14 /user/hive_external_table/access.log.2 [cloudera@quickstart ~]$ drop table intermediate_access_logs CREATE external TABLE intermediate_access_logs ( ip string, date string, method string, url string, http_version string, code1 string, code2 string, dash string, user_agent string ) ROW format serde &apos;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&apos; WITH serdeproperties ( &apos;input.regex&apos; = &apos;([^ ]*) - - \\[([^\\]]*)\\] &quot;([^\ ]*) ([^\ ]*) ([^\ ]*)&quot; (\\d*) (\\d*) &quot;([^&quot;]*)&quot; &quot;([^&quot;]*)&quot;&apos;, &apos;output.format.string&apos; = &quot;%1$$s %2$$s %3$$s %4$$s %5$$s %6$$s %7$$s %8$$s %9$$s&quot; ) LOCATION &apos; /user/hive_external_table/&apos; 如果删除外部表，目录和文件都不会被删除，即使是指定和默认目录一样（比如创建外部表的时候指定 location 为/user/hive/warehouse/products）如果是删除内部表，目录和文件都会被删除。即使是指定的为非默认目录，同样都会被删除（比如创建内部表时指定 location 为 /user/hive_external_table）指定了目录之后，如果目录下有文件，将会自动加载所有 CREATE EXTERNAL TABLE tokenized_access_logs ( ip STRING, date STRING, method STRING, url STRING, http_version STRING, code1 STRING, code2 STRING, dash STRING, user_agent STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; LOCATION &apos;/user/hive/warehouse/tokenized_access_logs&apos;; 跳出来，我们继续上面练习。 ADD JAR /usr/lib/hive/lib/hive-contrib.jar; INSERT OVERWRITE TABLE tokenized_access_logs SELECT * FROM intermediate_access_logs; 最后的查询会调用mapreduce任务（和sqoop一样），可以并行的将数据转移到tokenized_access_logs表中。上面提到过，对于新加的表，我们如果用impala的话，必须重新获取。 invalidate metadata; show tables 我们可以看到刚刚创建的两个外部表。 1 categories 2 customers 3 departments 4 intermediate_access_logs 5 order_items 6 orders 7 products 8 tb_test01 9 tokenized_access_logs 还是为了验证一下：查询url中包括product的url的总量，按照倒序排 1select count(*) as nums,url from tokenized_access_logs where url like &apos;%\/product\/%&apos; group by url order by nums desc 摘抄结果如下：（这里面要是有商品id可能会与下面的对比更明显些，nginx可以用cookie实现） nums url 1 1926 /department/apparel/category/cleats/product/Perfect%20Fitness%20Perfect%20Rip%20Deck 2 1793 /department/apparel/category/featured%20shops/product/adidas%20Kids&apos;%20RG%20III%20Mid%20Football%20Cleat 3 1780 /department/golf/category/women&apos;s%20apparel/product/Nike%20Men&apos;s%20Dri-FIT%20Victory%20Golf%20Polo 4 1757 /department/apparel/category/men&apos;s%20footwear/product/Nike%20Men&apos;s%20CJ%20Elite%202%20TD%20Football%20Cleat 5 1104 /department/fan%20shop/category/water%20sports/product/Pelican%20Sunstream%20100%20Kayak 6 1084 /department/fan%20shop/category/indoor/outdoor%20games/product/O&apos;Brien%20Men&apos;s%20Neoprene%20Life%20Vest 7 1059 /department/fan%20shop/category/camping%20&amp;%20hiking/product/Diamondback%20Women&apos;s%20Serene%20Classic%20Comfort%20Bi 8 1028 /department/fan%20shop/category/fishing/product/Field%20&amp;%20Stream%20Sportsman%2016%20Gun%20Fire%20Safe 9 1004 /department/footwear/category/cardio%20equipment/product/Nike%20Men&apos;s%20Free%205.0+%20Running%20Shoe 10 939 /department/footwear/category/fitness%20accessories/product/Under%20Armour%20Hustle%20Storm%20Medium%20Duffle%20Bag` 对数据很敏感的人会联想到上面我们的一个结果，是统计商品id，商品名字，和贡献收入的，再贴一下 1 1004 Field &amp; Stream Sportsman 16 Gun Fire Safe 6795260.4066467285 2 365 Perfect Fitness Perfect Rip Deck 4335357.441116333 3 957 Diamondback Women&apos;s Serene Classic Comfort Bi 4038330.9078979492 4 191 Nike Men&apos;s Free 5.0+ Running Shoe 3586941.2666854858 5 502 Nike Men&apos;s Dri-FIT Victory Golf Polo 3082050 6 1073 Pelican Sunstream 100 Kayak 3033648.3933258057 7 403 Nike Men&apos;s CJ Elite 2 TD Football Cleat 2831052.3296356201 8 1014 O&apos;Brien Men&apos;s Neoprene Life Vest 2830867.1741104126 9 627 Under Armour Girls&apos; Toddler Spine Surge Runni 1242929.2107200623 10 565 adidas Youth Germany Black/Red Away Match Soc 65940 通过简单对比，发现/department/apparel/category/featured%20shops/product/adidas%20Kids&#39;%20RG%20III%20Mid%20Football%20Cleat这个url访问的数量占据第二。 这里就会发现一些问题。 实践证明，如果米没有一个大数据的结构化的分析工具。统计出以上时间可能会花费很多时间。不排除自己搭建的平台的容错兼容分布式等维护问题带来的数据损失。 你帮老板发现了这个问题，老板很高兴，要给你资金支持。你准备大干一把了！ 实践三：市场部门要优化市场策略，想通过一些数据的交叉分析（关联性）把单独浏览量少的商品卖出去更多，或者再次统计一下倒数10的商品。 快速的大数据分析，那就是用到apache的spark了。我们可以构建一个spark任务，直观展示商品之间的关联。 通过以下命令执行 [cloudera@quickstart ~]$ spark-shell --master yarn-client Setting default log level to &quot;WARN&quot;. To adjust logging level use sc.setLogLevel(newLevel). SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.12.0.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] Welcome to ____ __ / __/__ ___ _____/ /__ _\ \/ _ \/ _ `/ __/ &apos;_/ /___/ .__/\_,_/_/ /_/\_\ version 1.6.0 /_/ Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_67) Type in expressions to have them evaluated. Type :help for more information. 18/04/23 19:59:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 18/04/23 19:59:59 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded. Spark context available as sc (master = yarn-client, app id = application_1524536469679_0001). SQL context available as sqlContext. 下一步，我们首先引入我们需要的类 import org.apache.hadoop.mapreduce.Job import org.apache.hadoop.mapreduce.lib.input.FileInputFormat import org.apache.avro.generic.GenericRecord import parquet.hadoop.ParquetInputFormat import parquet.avro.AvroReadSupport import org.apache.spark.rdd.RDD rdd是spark的核心，一个rdd可以理解为一个可以被分区的只读数据集（当然是分布式的）。一个rdd内有很多分区，分区内又有大量的数据记录。rdd的操作最终还是落到内存或者硬盘上。 下面我们创建一个rdd，提供给order_items和products表使用 def rddFromParquetHdfsFile(path: String): RDD[GenericRecord] = { val job = new Job() FileInputFormat.setInputPaths(job, path) ParquetInputFormat.setReadSupportClass(job, classOf[AvroReadSupport[GenericRecord]]) return sc.newAPIHadoopRDD(job.getConfiguration, classOf[ParquetInputFormat[GenericRecord]], classOf[Void], classOf[GenericRecord]).map(x =&gt; x._2) } val warehouse = &quot;hdfs://quickstart/user/hive/warehouse/&quot; val order_items = rddFromParquetHdfsFile(warehouse + &quot;order_items&quot;); val products = rddFromParquetHdfsFile(warehouse + &quot;products&quot;); 下一步，我们从order_items表和products表提取出我们想要的数据，以一个列表的形式存在，包含name和quantity，以order排序。 val orders = order_items.map { x =&gt; ( x.get(&quot;order_item_product_id&quot;), (x.get(&quot;order_item_order_id&quot;), x.get(&quot;order_item_quantity&quot;))) }.join( products.map { x =&gt; ( x.get(&quot;product_id&quot;), (x.get(&quot;product_name&quot;))) } ).map(x =&gt; ( scala.Int.unbox(x._2._1._1), // order_id ( scala.Int.unbox(x._2._1._2), // quantity x._2._2.toString // product_name ) )).groupByKey() 最后，我们衡量（tally）计算出订单中所有商品的组合次数，比如发现啤酒和纸尿裤这两个关联性特别高。按顺序排列拿到前10 val cooccurrences = orders.map(order =&gt; ( order._1, order._2.toList.combinations(2).map(order_pair =&gt; ( if (order_pair(0)._2 &lt; order_pair(1)._2) (order_pair(0)._2, order_pair(1)._2) else (order_pair(1)._2, order_pair(0)._2), order_pair(0)._1 * order_pair(1)._1 ) ) ) ) val combos = cooccurrences.flatMap(x =&gt; x._2).reduceByKey((a, b) =&gt; a + b) val mostCommon = combos.map(x =&gt; (x._2, x._1)).sortByKey(false).take(10) 最后打印结果 println(mostCommon.deep.mkString(&quot;\n&quot;)) exit 完整的代码如下： // First we&apos;re going to import the classes we need import org.apache.hadoop.mapreduce.Job import org.apache.hadoop.mapreduce.lib.input.FileInputFormat import org.apache.avro.generic.GenericRecord import parquet.hadoop.ParquetInputFormat import parquet.avro.AvroReadSupport import org.apache.spark.rdd.RDD // Then we create RDD&apos;s for 2 of the files we imported from MySQL with Sqoop // RDD&apos;s are Spark&apos;s data structures for working with distributed datasets def rddFromParquetHdfsFile(path: String): RDD[GenericRecord] = { val job = new Job() FileInputFormat.setInputPaths(job, path) ParquetInputFormat.setReadSupportClass(job, classOf[AvroReadSupport[GenericRecord]]) return sc.newAPIHadoopRDD(job.getConfiguration, classOf[ParquetInputFormat[GenericRecord]], classOf[Void], classOf[GenericRecord]).map(x =&gt; x._2) } val warehouse = &quot;hdfs://quickstart/user/hive/warehouse/&quot; val order_items = rddFromParquetHdfsFile(warehouse + &quot;order_items&quot;); val products = rddFromParquetHdfsFile(warehouse + &quot;products&quot;); // Next, we extract the fields from order_items and products that we care about // and get a list of every product, its name and quantity, grouped by order val orders = order_items.map { x =&gt; ( x.get(&quot;order_item_product_id&quot;), (x.get(&quot;order_item_order_id&quot;), x.get(&quot;order_item_quantity&quot;))) }.join( products.map { x =&gt; ( x.get(&quot;product_id&quot;), (x.get(&quot;product_name&quot;))) } ).map(x =&gt; ( scala.Int.unbox(x._2._1._1), // order_id ( scala.Int.unbox(x._2._1._2), // quantity x._2._2.toString // product_name ) )).groupByKey() // Finally, we tally how many times each combination of products appears // together in an order, then we sort them and take the 10 most common val cooccurrences = orders.map(order =&gt; ( order._1, order._2.toList.combinations(2).map(order_pair =&gt; ( if (order_pair(0)._2 &lt; order_pair(1)._2) (order_pair(0)._2, order_pair(1)._2) else (order_pair(1)._2, order_pair(0)._2), order_pair(0)._1 * order_pair(1)._1 ) ) ) ) val combos = cooccurrences.flatMap(x =&gt; x._2).reduceByKey((a, b) =&gt; a + b) val mostCommon = combos.map(x =&gt; (x._2, x._1)).sortByKey(false).take(10) // We print our results, 1 per line, and exit the Spark shell println(mostCommon.deep.mkString(&quot;\n&quot;)) exit 结果如下： scala&gt; println(mostCommon.deep.mkString(&quot;\n&quot;)) (67876,(Nike Men&apos;s Dri-FIT Victory Golf Polo,Perfect Fitness Perfect Rip Deck)) (62924,(O&apos;Brien Men&apos;s Neoprene Life Vest,Perfect Fitness Perfect Rip Deck)) (54399,(Nike Men&apos;s Dri-FIT Victory Golf Polo,O&apos;Brien Men&apos;s Neoprene Life Vest)) (39656,(Nike Men&apos;s Free 5.0+ Running Shoe,Perfect Fitness Perfect Rip Deck)) (39314,(Perfect Fitness Perfect Rip Deck,Perfect Fitness Perfect Rip Deck)) (35092,(Perfect Fitness Perfect Rip Deck,Under Armour Girls&apos; Toddler Spine Surge Runni)) (33750,(Nike Men&apos;s Dri-FIT Victory Golf Polo,Nike Men&apos;s Free 5.0+ Running Shoe)) (33406,(Nike Men&apos;s Free 5.0+ Running Shoe,O&apos;Brien Men&apos;s Neoprene Life Vest)) (29835,(Nike Men&apos;s Dri-FIT Victory Golf Polo,Nike Men&apos;s Dri-FIT Victory Golf Polo)) (29342,(Nike Men&apos;s Dri-FIT Victory Golf Polo,Under Armour Girls&apos; Toddler Spine Surge Run 简单的说，map就是通过提取过滤指定的字段，进行方法的invoke map。reduce是join &amp;&amp; group by。 如果没有spark这种分析工具，统计这些数据是很话费时间并且很困难。然后用scala几行代码。你就会分析出来订单中n多商品的相互关联性。并且花费很少时间。 翻篇儿： 领导找你：数据有问题，赶紧过来看，怎么干的事情！ 你:刚得瑟几天，怎么出大事了，赶紧去看看what happened 现在我们讲一讲实时的日志同步，并且以多维度去筛选。用到的是apache的flume 和apache的solr。钻取（drill down）和探取（exploration） solr以类sql形式组织数据。每条数据也是叫document（文档或者集合），每个文档包含字段（类似于mysql的schema），solr的数据很灵活，而且可以全文索引中某个字段。solr也是把数据分布式放在各个分片上。并且在查询的时候可以自动均衡，提高响应速度。 solr就不说了，现在都是elk了。。 完]]></content>
      <categories>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>HUE</tag>
        <tag>cdh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的架构和底层技术]]></title>
    <url>%2F2018%2F08%2F29%2Fdocker-one-03%2F</url>
    <content type="text"><![CDATA[简介 将物理设备和app用docker engine隔离 后台进程dockerd+rest api server+cli接口（docker）（cs架构）3.docker version 123456789101112131415161718 client: Version: 18.09.6 API version: 1.39 Go version: go1.10.8 Git commit: 481bc77 Built: Sat May 4 02:35:27 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.6 API version: 1.39 (minimum version 1.12) Go version: go1.10.8 Git commit: 481bc77 Built: Sat May 4 01:59:36 2019 OS/Arch: linux/amd64 Experimental: false containers + images + registry 底层技术支持 namespace；做隔离pid，net，ipc，mnt，uts control groups：做资源控制，内存 cpu等 union file systems：container 和image的分层 实验环境介绍 docker image镜像 image概念 文件和meta data的集合（root filesystem） 分层，每层都可以添加改变删除文件，成为一个新的image 不同的image可以共享相同的layer image本身是read only linux内核和发行版和基于一些应用软件都可以看做是docker的分层 12345678910111213root@swoole_dev:/home/tb# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest fce289e99eb9 5 months ago 1.84kBroot@swoole_dev:/home/tb# docker run centosUnable to find image &apos;centos:latest&apos; locallylatest: Pulling from library/centos8ba884070f61: Pull complete Digest: sha256:ca58fe458b8d94bc6e3072f1cfbd334855858e05e1fd633aa07cf7f82b048e66Status: Downloaded newer image for centos:latestroot@swoole_dev:/home/tb# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 9f38484d220f 3 months ago 202MBhello-world latest fce289e99eb9 5 months ago 1.84kB 为啥centos这么小，因为他是基本地于linux kernel的基础之上 image的获取方式 dockerfile，build from ubuntu：14.04 基于的base kernel label 说明 run 执行的命令 expose 暴露的端口 entrypoint：程序起点，入口 docker build -t tongbo/redis: latest .,.代表当前目录 执行build的每一行的id就是一层封装，层之间可以互用 pull from registry(类似github,默认的为dockerhub) docker pull ubuntu:14.04 docker push （to server） 12345678910111213141516171819root@swoole_dev:/home/tb# docker pull redis:3.23.2: Pulling from library/redisf17d81b4b692: Pull complete b32474098757: Pull complete 8980cabe8bc2: Pull complete 58af19693e78: Pull complete a977782cf22d: Pull complete 9c1e268980b7: Pull complete Digest: sha256:43d2f5e7338ef56b3bda52f1ba7b9b58866c07141e834f64267afb51c89e5086Status: Downloaded newer image for redis:3.2root@swoole_dev:/home/tb# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 9f38484d220f 3 months ago 202MBhello-world latest fce289e99eb9 5 months ago 1.84kBredis 3.2 87856cc39862 8 months ago 76MBroot@swoole_dev:/home/tb# docker search redisNAME DESCRIPTION STARS OFFICIAL AUTOMATEDredis Redis is an open source key-value store that… 7029 [OK] bitnami/redis Bitnami Redis Docker Image 114 dockerhub offical 第三方的，pull的时候需要增加用户名/镜像名字 制作base image 比如制作一个u2dev的base 小技巧：如何去掉sudo，sudo groupadd docker sudo gpasswd -a vargant docker service docker restart 以hello-world的image为例 tag digest（摘要，消化理解） status more ambitious（有野心的，有兴趣的）- 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 编辑dockerfile文件FROM scratch #base的image，所以从开始不需要ADD hello / #把helloadd到image的根目录里CMD [&quot;/hello&quot;] #执行脚本命令#build，根据dockerfile，一共三步@swoole_dev:/home/tb/my_docker_helloworld# docker build -t tongbo/hello_world .Sending build context to Docker daemon 12.29kBStep 1/3 : FROM scratch ---&gt; Step 2/3 : ADD hello / ---&gt; b89e60e00ca1Step 3/3 : CMD [&quot;/hello&quot;] ---&gt; Running in 13d1d20bd719Removing intermediate container 13d1d20bd719 ---&gt; 462eb2d91ad7Successfully built 462eb2d91ad7Successfully tagged tongbo/hello_world:latestroot@swoole_dev:/home/tb/my_docker_helloworld# #build成功，查看结果root@swoole_dev:/home/tb/my_docker_helloworld# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEtongbo/hello_world latest 462eb2d91ad7 55 seconds ago 8.6kBcentos latest 9f38484d220f 3 months ago 202MBhello-world latest fce289e99eb9 5 months ago 1.84kBredis 3.2 87856cc39862 8 months ago 76MBroot@swoole_dev:/home/tb/my_docker_helloworld# # 查看镜像分层（因from scratch，所以这里是两层）root@swoole_dev:/home/tb/my_docker_helloworld# docker history 462eb2d91ad7IMAGE CREATED CREATED BY SIZE COMMENT462eb2d91ad7 3 minutes ago /bin/sh -c #(nop) CMD [&quot;/hello&quot;] 0B b89e60e00ca1 3 minutes ago /bin/sh -c #(nop) ADD file:ab92082ce376d310a… 8.6kB root@swoole_dev:/home/tb/my_docker_helloworld## build 自己的镜像时候必须是gcc -static,否则报文件不存在,==这是为啥内==# -static 是让 gcc 进行静态编译，也就是把所有都需要的函数库都集成进编译出来的程序上，这个程序就可以不依赖外部的函数库运行了。root@swoole_dev:/home/tb/my_docker_helloworld# docker run tongbo/hello_worldstandard_init_linux.go:207: exec user process caused &quot;no such file or directoryroot@swoole_dev:/home/tb/my_docker_helloworld# gcc -static hello.c -o helloroot@swoole_dev:/home/tb/my_docker_helloworld# docker build -t tongbo/hello_world .Sending build context to Docker daemon 916.5kBStep 1/3 : FROM scratch ---&gt; Step 2/3 : ADD hello / ---&gt; Using cache ---&gt; 11b009df24b2Step 3/3 : CMD [&quot;/hello&quot;] ---&gt; Using cache ---&gt; 6c539eb137ddSuccessfully built 6c539eb137ddSuccessfully tagged tongbo/hello_world:latestroot@swoole_dev:/home/tb/my_docker_helloworld# docker run tongbo/hello_worldhello,world,docker in c 什么是container container是通过image创建（copy）的 container是在image上的基础上增加类一层，叫做container layer，后者是可读写 的，注意image是只读的 理解： 类为image，实例为container image负责app的存储和分发，container负责运行 基于image 创建container docker run image docker container ls：查看当前正在运行的容器 docker container ls -a：查看当前运行和已经运行完成退出的 123root@swoole_dev:/home/tb/my_docker_helloworld# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES51869bc1fcd5 tongbo/hello_world &quot;/hello&quot; 7 minutes ago Exited (0) 7 minutes ago happy_bardeen docker run centos:注意一般run会走latest的版本，如果指定类版本，必须加上，否则会先pull一份过来,下面的执行centos ，==也只是走类bin/bash,why？== 1234567root@swoole_dev:/home/tb/my_docker_helloworld# docker run centosroot@swoole_dev:/home/tb/my_docker_helloworld# docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESroot@swoole_dev:/home/tb/my_docker_helloworld# docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES35f4015c37be centos &quot;/bin/bash&quot; 20 seconds ago Exited (0) 18 seconds ago gallant_boyd51869bc1fcd5 tongbo/hello_world &quot;/hello&quot; 11 minutes ago Exited (0) 11 minutes ago happy_bardeen 交互式运行 docker run -it centos123456789101112# 终端1，ununtu环境root@swoole_dev:/etc/docker# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES29fae6a620a9 centos &quot;/bin/bash&quot; 47 seconds ago Up 46 seconds affectionate_meitnerroot@swoole_dev:/etc/docker# docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES29fae6a620a9 centos &quot;/bin/bash&quot; 51 seconds ago Up 49 seconds affectionate_meitnerroot@swoole_dev:/etc/docker# # run -it centos 效果，-i为interactive，-t为tty，通过执行 docker run --help查看，完成操作后再容器内退出，退出后容器不会运行[root@29fae6a620a9 /]# cat /etc/redhat-releaseCentOS Linux release 7.6.1810 (Core) [root@29fae6a620a9 /]# docker的management commands和commands Management Commands: 123456789101112131415builder Manage buildsconfig Manage Docker configscontainer Manage containersengine Manage the docker engineimage Manage imagesnetwork Manage networksnode Manage Swarm nodesplugin Manage pluginssecret Manage Docker secretsservice Manage servicesstack Manage Docker stacksswarm Manage Swarmsystem Manage Dockertrust Manage trust on Docker imagesvolume Manage volumes 一些简写 命令 docker rmi imageid docker rm containerid docker ps -a 当前的container docker container ls -aq 列出所有的container id docker rm $(docker container ls -aq) rm所有的container 结合xargs grep awk docker container ls -f “status=exited” -q 删除所有exited的container 构建自己的docker镜像 docker container commit Usage: docker container commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] Create a new image from a container’s changes 简写为 docker commit docker build build an image from a dockerfile 操作步骤 docker run -it centos yum install vim exit docker container ls -a |grep centos 4中的centos 安装了vim docker container ls -a |grep centos 0f5ccf1365eb centos &quot;/bin/bash&quot; 3 minutes ago Exited (0) About a minute ago pedantic_gagarin 12345678root@swoole_dev:/home/tb# docker commit pedantic_gagarin yaxiaomu/centos_add_vim:default_yaxiaomu_tagsha256:3204e122d66ce500790269c1fed291842b6f18c34286647212d9293c9f56cb45root@swoole_dev:/home/tb# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEyaxiaomu/centos_add_vim default_yaxiaomu_tag 3204e122d66c 10 seconds ago 361MBtongbo/hello_world latest 6c539eb137dd 17 hours ago 913kBcentos latest 9f38484d220f 3 months ago 202MBredis 3.2 87856cc39862 8 months ago 76MB 注意centos和centos_add_vim这两个image会共享很多的layer:9f38484d220f 1234567891011121314151617root@swoole_dev:/home/tb# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEyaxiaomu/centos_add_vim default_yaxiaomu_tag 3204e122d66c 3 minutes ago 361MBtongbo/hello_world latest 6c539eb137dd 17 hours ago 913kBcentos latest 9f38484d220f 3 months ago 202MBredis 3.2 87856cc39862 8 months ago 76MBroot@swoole_dev:/home/tb# docker history 9f38484d220fIMAGE CREATED CREATED BY SIZE COMMENT9f38484d220f 3 months ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0B &lt;missing&gt; 3 months ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B &lt;missing&gt; 3 months ago /bin/sh -c #(nop) ADD file:074f2c974463ab38c… 202MB root@swoole_dev:/home/tb# docker history 3204e122d66cIMAGE CREATED CREATED BY SIZE COMMENT3204e122d66c 3 minutes ago /bin/bash 160MB 9f38484d220f 3 months ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0B &lt;missing&gt; 3 months ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B &lt;missing&gt; 3 months ago /bin/sh -c #(nop) ADD file:074f2c974463ab38c… 202MB 不提倡以上方式创建，提倡用dockerfile，再build 123456789101112131415#如何在docker image里yum呢，image不是只读的吗# 答：会产生临时的container，然后再写，然后再commit root@swoole_dev:/home/tb/docker-centos-vim# docker build -t tongbo/centos_add_vim . Sending build context to Docker daemon 2.048kBStep 1/2 : FROM centos ---&gt; 9f38484d220fStep 2/2 : RUN yum install -y vim ---&gt; Running in 67aeb36048ffLoaded plugins: fastestmirror, ovl... Complete!Removing intermediate container 67aeb36048ff ---&gt; 907325d6fc6bSuccessfully built 907325d6fc6bSuccessfully tagged tongbo/centos_add_vim:latest dockerfile语法梳理和最佳实践 FROM [scratch centos ubuntu:14:04] #制作|使用base image 尽量使用官方image LABEL metadata autohr verison description RUN yum install |apt-get update(注意执行命令都会有新的一层layer，尽量合并成一个语句（&amp;&amp;连接，反斜线\换行），减少层数) workdir /root |demo |pwd(如果没有目录会再当前目录自动创建，注意使用绝对目录) ADD把本地文件条件，添加到image的根目录里去，也可以解压缩 ADD test.tar.gz/ # 添加到根目录并解压 COPY ，大部分情况使用copy，如果添加远程文件用curl 或者wget ENV mysql_version 5.6 # 设置常量, 保证可维护性 123ENV MYSQL_VERSION 5.6 RUN apt-get instlal -y mysql-server= &quot;$&#123;MYSSQL_VERSION&#125;&quot; \&amp;&amp; rm -rf /var/lib/apt/lists/* volume 和rescource CMD and entrypoint docker-library on github， reference run vs cmd vs encrypoint run：执行命令并创建新的image layer cmd：设置容器启动后默认执行的命令和参数 如果docker run指定了其他命令，cmd命令会被忽略 docker run -it [image] /bin/bash 如果定义类多个cmd，仅有最后一个被执行 entrypoint：设置容器启动时运行的命令 不会被忽略，一定会执行，即使指定了其他命令（区别于cmd） 让容器以应用程序或者服务的形式运行 实践：写一个shell脚本作为entrypoint - 两种格式 shell格式 run echo “hello” exec格式 [“/bin/echo”,’hello’] 如果是exec格式，需要显示指定如下123FROM centosEVN name DockerENTRYPOIN [&quot;/bin/bash&quot;,&quot;-c&quot;,&quot;echo hello $name&quot;] image的分发 dockerhub docker login docker image push 12345678910111213141516171819202122root@swoole_dev:/home/tb/my_docker_helloworld# docker push yaxiaomu/hello_world:latestThe push refers to repository [docker.io/yaxiaomu/hello_world]096f9105d9f4: Pushed latest: digest: sha256:dc9c69395640d5fd7cb9e4f8bd2bdbf788b206a59e942a2a40577d9b1c089934 size: 527root@swoole_dev:/home/tb/my_docker_helloworld# # 注意image必须是dockerid的用户名，否则会说：denied: requested access to the resource is denied# 本地删除后再次从docker hub上pullroot@swoole_dev:/home/tb/my_docker_helloworld# docker run yaxiaomu/hello_worldhello,world,docker in croot@swoole_dev:/home/tb/my_docker_helloworld# docker rm yaxiaomu/hello_worldError: No such container: yaxiaomu/hello_worldroot@swoole_dev:/home/tb/my_docker_helloworld# docker rmi yaxiaomu/hello_worldUntagged: yaxiaomu/hello_world:latestUntagged: yaxiaomu/hello_world@sha256:dc9c69395640d5fd7cb9e4f8bd2bdbf788b206a59e942a2a40577d9b1c089934root@swoole_dev:/home/tb/my_docker_helloworld# docker run yaxiaomu/hello_worldUnable to find image &apos;yaxiaomu/hello_world:latest&apos; locallylatest: Pulling from yaxiaomu/hello_worldDigest: sha256:dc9c69395640d5fd7cb9e4f8bd2bdbf788b206a59e942a2a40577d9b1c089934Status: Downloaded newer image for yaxiaomu/hello_world:latesthello,world,docker in croot@swoole_dev:/home/tb/my_docker_helloworld# 因为安全因素考虑，分享image不如分享Dockerfile 可以通过和github关联，自动拉取指定项目下的dockerfile，自动build 私有本地仓库搭建，但没有图形化界面：docker run -d -p 5000:5000 –restart always –name registry registry:2 可以向指定私有库提交docker built -t serverip:port/name:tag 安全性修改，创建文件/etc/docker/daemon.json deamon.json,配置加入 insecure-registries: ip :端口 再修改 root@swoole_dev:/etc/init.d# vim /lib/systemd/system/docker.service,增加一行：EnvironmentFile=/etc/docker/daemon.json 重启docker服务 service docker restart 通过docker registry api 查看 ，http查看 记录在了segmentfault dockerfile实战 flask demo，把python程序打包成image，运行container 准备一个带pyhton的base image 需要安装flask 需要运行起来app 操作步骤 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566root@swoole_dev:/home/tb/flask_demo# more app.py ## app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello(): return &quot;hello,tb de docker&quot;if __name__ == &apos;__main__&apos;: app.run()# 安装软件apt-get install python-minimalapt install python-pippip install flask# 运行结果 root@swoole_dev:/home/tb/flask_demo# python app.py * Serving Flask app &quot;app&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 127.0.0.1 - - [22/Jun/2019 21:00:05] &quot;GET / HTTP/1.1&quot; 200 -#dockerfile ,注意cppy的 app.py为写成类绝对路径报错类，那就转移到当前目录下吧。FROM python:2.7LABEL maintainer=&quot;tongbo&lt;demo.com@126.com&gt;&quot;RUN pip install flaskCOPY app.py /app/WORKDIR /appEXPOSE 5000CMD [&quot;pyhton&quot;,&quot;app.py&quot;]# buildroot@swoole_dev:/home/tb/flask_hello_world# docker build -t yaxiaomu/flask_demo:latest .Sending build context to Docker daemon 3.072kBStep 1/7 : FROM python:2.7 ---&gt; 37093962fbf5Step 2/7 : LABEL maintainer=&quot;tongbo&lt;demo.com@126.com&gt;&quot; ---&gt; Using cache ---&gt; c4ac0caa5aabStep 3/7 : RUN pip install flask ---&gt; Using cache ---&gt; 60c7e35f23a3Step 4/7 : COPY app.py /app/ ---&gt; a7a69c1da0b6Step 5/7 : WORKDIR /app ---&gt; Running in 2122fe24efd6Removing intermediate container 2122fe24efd6 ---&gt; f6b586c33cbcStep 6/7 : EXPOSE 5000 ---&gt; Running in e368df4c5205Removing intermediate container e368df4c5205 ---&gt; 6a7e1858c5e7Step 7/7 : CMD [&quot;pyhton&quot;,&quot;app.py&quot;] ---&gt; Running in e8c96756cc9eRemoving intermediate container e8c96756cc9e ---&gt; c37bb4c557daSuccessfully built c37bb4c557daSuccessfully tagged yaxiaomu/flask_demo:latest## 运行container，报错root@swoole_dev:/home/tb/flask_hello_world# docker run yaxiaomu/flask_demodocker: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused &quot;exec: \&quot;pyhton\&quot;: executable file not found in $PATH&quot;: unknown.ERRO[0000] error waiting for container: context canceled debug 针对创建临时中间状态的image，根据image id进入/bin/bash docker run it imageid /bin/bash cd .. &amp;&amp; begin your debug 123456789101112131415161718192021root@swoole_dev:/home/tb/flask_hello_world# docker run -it c37bb4c557da /bin/bashroot@a972581ff13e:/app#root@a972581ff13e:/app# python app.py * Serving Flask app &quot;app&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) ## 看结果明明可以运行，再看报错，原来是python写成pyhton了。改一下dockerfile，成功了 root@swoole_dev:/home/tb/flask_hello_world# docker run yaxiaomu/flask_demo * Serving Flask app &quot;app&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) ## 后台运行 docker run -d,--name 增加名字，删除启动时可用 root@swoole_dev:/home/tb/flask_hello_world# docker run -d --name tb_demo yaxiaomu/flask_demo e7841af659ab469f598151b0f43c1333a77a52c6610d6894a5dfbec887d6848e 容器的操作 docker container stop 664f2033265b | docker stop 664 664f2033265b [1]+ Exit 137 docker run yaxiaomu/flask_demo root@swoole_dev:/home/tb/flask_hello_world# docker exec -it e7841af659ab /bin/bash root@e7841af659ab:/app# docker exec -it e7841af659ab ip a docker rm $(docker ps -aq) docker start|stop demo docker inspect containerId # 查看完整追踪 docker container logs containerid docker container commands… dockerfile实战2 stress工具 apt-get install stress 测试主机 或者容器资源（内存、cpu等） 每个docker启动的时候都可以限制cpu 内存等1234567FROM UBUNTURUN apt-get update &amp;&amp; apt-get install -y stressENTRYPOINT [&quot;usr/bin/stress&quot;]CMD ## 运行docker run -it yaxiaomu/ubuntu_stress --vm 1 --verbose 容器的资源限制 物理机-虚拟机之间的资源配置 virtualbox -m 限制memory swap memory -c cpu shares relate weight,相对两倍权重 docker run –cpu-shares=5 –name=test2 –cpu1 docker run –cpu-shares=10 –name=test3 –cpu1 control groups，分层layer通过union file system实现 完]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php的调用链追踪入门（jeager）]]></title>
    <url>%2F2018%2F08%2F13%2Ftrace-jaeger-php%2F</url>
    <content type="text"><![CDATA[简单介绍 用途：监控monitor 检测troubleshoot 事务transations 处理在复杂的分布式系统中 complex distributed systems 性能优化分析 官网地址 背景：微服务（microservices）的发展、网络的不稳定、多环的服务请求记录错误排查定位 相关： 轻量级标准化层API：OpenTracing jagger前世今生 阿里好文 openttacing api 中文版介绍 七牛 阿里好文2 google 论文中文 两对儿图： 日常调用（逻辑链路） 链路分析（物理链路） 整图 名词介绍 TrancesID 全局跟踪id，标记一次完整的服务调用（可包含多次子，子子调用） 一般可以设置为TraceId和顶级span相同 SpansID 一次方法（程序块、RPC、db）的调用，每一个RPC对应到一个单一的span，但是traceId都是相同的。 注意：一个节点上可能有多次span（可能此端相对上游来说是服务端，接收和应答上游服务。对于下游（下游）可能有多个，又会是调用和接收下游的服务），不能把一个节点上的多个span合并成一个。 一个节点上并不总是发生完整的cs sr ss cr这四种事件。因为并不是所有的节点都有上游服务和下游服务。 Spans Tags span日志集合（key-value） Baggage Item Trace层面的日志数据 Refererneces Span之间的关系 grpc protobuf thrift 跨语言通信框架（协议） 事件（annotation数据）类型 cs ：客户端/消费者发起请求 client send cr ：客户端/消费者收到应答 client recevive sr ：服务端/生产者接收到请求 server receive ss ：服务端/生产者发送应答 server send Annotation的意思是注释，备注，很好理解。可以理解为一个Hash结构，长度最多为4.每种关键事件包含value， timestamp，和endpoint。value为以上四种事件类型之一，timestamp即为发生调用时间。enpoint用于记录发生的机器ip和服务名称servername。所以一般cs和cr的机器名称相等，sr和ss的机器名称相同 duration 时间消耗总耗时 timestamp 一般用于记录时间消耗的起点 endpoint 记录终端机器发生的ip和名称（可以是相对的发起方和调用方），也会把endpoint数据放在annotation里。 BinaryAnnotation 除去以上的时间、事件、节点等信息，如果还需要++绑定业务数据++（日志、异常），将数据写入到BinaryAnnotion中。结构和Annotation一样。 parentId 父span的Id，当然具有层级关系。顶级span（最先接触服务调用入口）是没有parentId的 span name 一般为接口的方法名 一图胜三言(下图) 大概流程 请求入口生成唯一traceId，用于贯穿整个服务， 在调用具体的服务（或方法）前生成span（spanid可以平行、嵌套，），记录调用时间 在调用具体的服务（或方法）时，传参1的traceId和2的spanid，调用http server或者rpc server 调用完成后关联到1的traceId 统一存储（涉及各编程语言调用类库及客户端收集存储） 查询结果，输出展示应用场景 做一个筛选条件的导出excel操作，筛选条件经过sql查询生成对象数组，然后经过代码逻辑处理导出csv，查看是否有redis缓存，最后到客户端输出。可以查看是sql问题（数据查询和数据转换）？redis连接缓存问题？客户端导出慢？ 谷歌首页搜索一个词语，需要毫秒级响应。列表，图片，推荐，所有的不只一个接口。如果时间太长，到底是哪里慢？ 组成部分 前端UI展示 数据持久化存储（Cassandra or elastic） 数据查询组件 客户端库library（Go, Node, Java, Python） 客户端代理anent（可控制应用追踪数据采样） 数据收集处理collector 数据收集展示流程123Agent --&gt; Collector # 从Agent发送数据到CollectorCollector --&gt; Cassandra # 从Collector写数据到CassandraQuery --&gt; Cassandra # 从Cassandra读数据到Query ALL IN ONE DOCKER IMAGE 仅供测试环境，数据放在内存中了 -docker images 12345678910docker run -d --name jaeger \ -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \ -p 5775:5775/udp \ -p 6831:6831/udp \ -p 6832:6832/udp \ -p 5778:5778 \ -p 16686:16686 \ -p 14268:14268 \ -p 9411:9411 \ jaegertracing/all-in-one:latest 模拟测试数据方法一： Hot R.O.D. Rides OnDemand 1234567891011121314root@docker_001:/home/tb# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEjaegertracing/example-hotrod latest 73985981101a 12 hours ago 15.5MBjaegertracing/all-in-one latest 8ab45e1d2c89 4 days ago 40.4MBredislabs/rebloom latest 3386f3e4e33a 4 weeks ago 83.6MBtb_php-fpm latest ddd54dd40a46 4 months ago 225MBnginx latest c5c4e8fa2cf7 4 months ago 109MBphpdockerio/php56-fpm latest e944c32c61aa 5 months ago 225MBhello-world latest f2a91732366c 9 months ago 1.85kBroot@docker_001:/home/tb# docker run --rm --link jaeger -p8080-8083:8080-8083 jaegertracing/example-hotrod:latest all --jaeger-agent.host-port=jaeger:68312018-08-28T06:44:27.000Z INFO cmd/root.go:86 Using expvar as metrics backend2018-08-28T06:44:27.000Z INFO cmd/all.go:25 Starting all services2018-08-28T06:44:27.104Z INFO log/logger.go:37 Starting &#123;&quot;service&quot;: &quot;route&quot;, &quot;address&quot;: &quot;http://0.0.0.0:8083&quot;&#125;2018-08-28T06:44:27.105Z INFO log/logger.go:37 Starting &#123;&quot;service&quot;: &quot;frontend&quot;, &quot;address&quot;: &quot;http://0.0.0.0:8080&quot;&#125; 模拟数据方法二 go源码安装123456 go get github.com/jaegertracing/jaeger cd $GOPATH/src/github.com/jaegertracing/jaeger make install ``` ## 问题：glide (go 包管理工具)的安装 /bin/sh: 1: glide: not found glide install make: glide: Command not found Makefile:158: recipe for target &apos;install&apos; failed make: *** [install] Error 127 ## 安装glide curl https://glide.sh/get | sh % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 4833 100 4833 0 0 944 0 0:00:05 0:00:05 --:--:-- 1192 ARCH=amd64 OS=linux Using curl as download tool Getting https://glide.sh/version TAG=v0.13.1 GLIDE_DIST=glide-v0.13.1-linux-amd64.tar.gz Downloading https://github.com/Masterminds/glide/releases/download/v0.13.1/glide-v0.13.1-linux-amd64.tar.gz glide not found. Did you add $GOBIN to your $PATH? Fail to install glide root@docker_001:/home/tb/go_work/src/github.com/jaegertracing/jaeger# 12345 解决问题： `vim .profile` # 增加GOBIN的PATH 然后 vim .profile # 增加GOBIN的PATH source .profile root@docker_001:/home/tb# echo $GOBIN /usr/local/go/bin root@docker_001:/home/tb# cd /home/tb/go_work/src/github.com/jaegertracing/jaeger root@docker_001:/home/tb/go_work/src/github.com/jaegertracing/jaeger# root@docker_001:/home/tb/go_work/src/github.com/jaegertracing/jaeger# curl https://glide.sh/get | sh % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 4833 100 4833 0 0 481 0 0:00:10 0:00:10 --:--:-- 1120 ARCH=amd64 OS=linux Using curl as download tool Getting https://glide.sh/version TAG=v0.13.1 GLIDE_DIST=glide-v0.13.1-linux-amd64.tar.gz Downloading https://github.com/Masterminds/glide/releases/download/v0.13.1/glide-v0.13.1-linux-amd64.tar.gz glide version v0.13.1 installed successfully 然后执行 make install cd examples/hotrod go run ./main.go all,执行结果如下 ``` [INFO] –&gt; Exporting go.uber.org/multierr [INFO] –&gt; Exporting go.uber.org/zap [INFO] Replacing existing vendor dependencies root@docker_001:/home/tb/go_work/src/github.com/jaegertracing/jaeger# cd examples/hotrod root@docker_001:/home/tb/go_work/src/github.com/jaegertracing/jaeger/examples/hotrod# go run ./main.go all 2018-08-30T11:57:49.524+0800 INFO cmd/root.go:86 Using expvar as metrics backend 2018-08-30T11:57:49.524+0800 INFO cmd/all.go:25 Starting all services 2018-08-30T11:57:49.625+0800 INFO log/logger.go:37 Starting {“service”: “route”, “address”: “http://0.0.0.0:8083&quot;} 2018-08-30T11:57:49.626+0800 INFO log/logger.go:37 Starting {“service”: “frontend”, “address”: “http://0.0.0.0:8080&quot;} 2018-08-30T11:57:49.728+0800 INFO log/logger.go:37 Starting {“service”: “customer”, “address”: “http://0.0.0.0:8081&quot;} 2018-08-30T11:57:49.729+0800 INFO log/logger.go:37 TChannel listening {“service”: “driver”, “hostPort”: “[::]:8082”} … 也是同样通过8080端口访问即可。 todo elasticsearch 存储信息 php 调用追踪 源码安装jaeger zipkin高清大图]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>traceing</tag>
        <tag>jaeger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker环境的各种搭建方法]]></title>
    <url>%2F2018%2F07%2F25%2Fdocker-one-02%2F</url>
    <content type="text"><![CDATA[install docker 登录 id.docker.com download win desktop:必须win10&amp; hyper-v mac decktop &amp;kitematic :gui container 注意如果下载了win的docker，那么在win上的virtualbox无法使用 建议还是使用虚机 vagrant工具 vagrant init vagrant up vagrant destory vagrant destory vagrant file vagrant file cloud find ubuntu 可以多台同时执行 win上安装vargant安装centos7 123456789101112131415161718192021C:\Users\volvo&gt;cd vagrant C:\Users\volvo\vagrant&gt;ls &apos;ls&apos; 不是内部或外部命令，也不是可运行的程序 或批处理文件。 C:\Users\volvo\vagrant&gt;mkdir centos7 C:\Users\volvo\vagrant&gt;cd centos7 C:\Users\volvo\vagrant\centos7&gt;vagrant init centos/7 C:\Users\volvo\vagrant\centos7&gt;vagrant init centos/7 A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant. C:\Users\volvo\vagrant\centos7&gt;vagrant up Bringing machine &apos;default&apos; up with &apos;virtualbox&apos; provider... vagrant ssh 在u2dev虚拟机安装docker的过程 https://www.runoob.com/docker/ubuntu-docker-install.html docker machine，玩云上的，本机的各种docker docker clint &amp; docker server &amp; more docker driver 安装base=https://github.com/docker/machine/releases/download/v0.16.0 &amp;&amp; curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp; sudo install /tmp/docker-machine /usr/local/bin/docker-machine docker-machline-driver，可以通过tcp或者unix sock的方式创建和维护d本地和远程docker,可以在官方找到driver，通过access_key 及 access_id来鉴权登录,region可选，通过docker-machine ssh $docker_uanme进入到远程的docker server，可以通过eval命令更改本地的环境主体。 docker playground ：https://labs.play-with-docker.com 完]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php的调用链追踪入门（zipkin）]]></title>
    <url>%2F2018%2F07%2F23%2Ftrace-zipkin-php%2F</url>
    <content type="text"><![CDATA[学名（Distributed TracingSystem 分布式追踪系统）支持的客户端语言情况奉上谷歌论文Dapper新美大之CAT（开源）大厂子自己造的轮子安装运行 代码执行 12345678910111213141516171819202122232425262728root@es_002:/home/tb/tbdown/zipkin# lsquickstart.sh zipkin-server-2.11.7-exec.jarroot@es_002:/home/tb/tbdown/zipkin# java -jar zipkin-server-2.11.7-exec.jar ******** ** ** * * ** ** ** ** ** ** ** ** ******** **** **** **** **** ****** **** *** **************************************************************************** ******* **** *** **** **** ** ** ***** ** ***** ** ** ** ** ** ** ** ** * *** ** **** ** ** ** ***** **** ** ** *** ****** ** ** ** ** ** ** **:: Powered by Spring Boot :: 上图 是没有jaeger的好看，丰富 有数据的 依赖 逻辑图 总 分 层次 更贴近业务的复杂调用 Zipkin of php类库了解一下 123456789101112//如果是新项目需要引入包，按需参考以下命令composer initcomposer config -g secure-http false//参考官方php类库 composer.json文件，得到以下root@udev:/home/tb/tbtmp# lscomposer.json composer.lock vendorroot@udev:/home/tb/tbtmp# cd vendor/root@udev:/home/tb/tbtmp/vendor# lsautoload.php composer evenement jcchavezs phpdocumentor phpunit react sebastian symfonybin doctrine guzzlehttp myclabs phpspec psr ringcentral squizlabs webmozartroot@udev:/home/tb/tbtmp/vendor# Zipkin of php类库了解一下 123456789101112//如果是新项目需要引入包，按需参考以下命令composer initcomposer config -g secure-http false//参考官方php类库 composer.json文件，得到以下root@udev:/home/tb/tbtmp# lscomposer.json composer.lock vendorroot@udev:/home/tb/tbtmp# cd vendor/root@udev:/home/tb/tbtmp/vendor# lsautoload.php composer evenement jcchavezs phpdocumentor phpunit react sebastian symfonybin doctrine guzzlehttp myclabs phpspec psr ringcentral squizlabs webmozartroot@udev:/home/tb/tbtmp/vendor# 数据持久化到mysql 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950create database zipkin;CREATE TABLE IF NOT EXISTS zipkin_spans ( `trace_id_high` BIGINT NOT NULL DEFAULT 0 COMMENT &apos;If non zero, this means the trace uses 128 bit traceIds instead of 64 bit&apos;, `trace_id` BIGINT NOT NULL, `id` BIGINT NOT NULL, `name` VARCHAR(255) NOT NULL, `parent_id` BIGINT, `debug` BIT(1), `start_ts` BIGINT COMMENT &apos;Span.timestamp(): epoch micros used for endTs query and to implement TTL&apos;, `duration` BIGINT COMMENT &apos;Span.duration(): micros used for minDuration and maxDuration query&apos;) ENGINE=InnoDB ROW_FORMAT=COMPRESSED CHARACTER SET=utf8 COLLATE utf8_general_ci;ALTER TABLE zipkin_spans ADD UNIQUE KEY(`trace_id_high`, `trace_id`, `id`) COMMENT &apos;ignore insert on duplicate&apos;;ALTER TABLE zipkin_spans ADD INDEX(`trace_id_high`, `trace_id`, `id`) COMMENT &apos;for joining with zipkin_annotations&apos;;ALTER TABLE zipkin_spans ADD INDEX(`trace_id_high`, `trace_id`) COMMENT &apos;for getTracesByIds&apos;;ALTER TABLE zipkin_spans ADD INDEX(`name`) COMMENT &apos;for getTraces and getSpanNames&apos;;ALTER TABLE zipkin_spans ADD INDEX(`start_ts`) COMMENT &apos;for getTraces ordering and range&apos;;CREATE TABLE IF NOT EXISTS zipkin_annotations ( `trace_id_high` BIGINT NOT NULL DEFAULT 0 COMMENT &apos;If non zero, this means the trace uses 128 bit traceIds instead of 64 bit&apos;, `trace_id` BIGINT NOT NULL COMMENT &apos;coincides with zipkin_spans.trace_id&apos;, `span_id` BIGINT NOT NULL COMMENT &apos;coincides with zipkin_spans.id&apos;, `a_key` VARCHAR(255) NOT NULL COMMENT &apos;BinaryAnnotation.key or Annotation.value if type == -1&apos;, `a_value` BLOB COMMENT &apos;BinaryAnnotation.value(), which must be smaller than 64KB&apos;, `a_type` INT NOT NULL COMMENT &apos;BinaryAnnotation.type() or -1 if Annotation&apos;, `a_timestamp` BIGINT COMMENT &apos;Used to implement TTL; Annotation.timestamp or zipkin_spans.timestamp&apos;, `endpoint_ipv4` INT COMMENT &apos;Null when Binary/Annotation.endpoint is null&apos;, `endpoint_ipv6` BINARY(16) COMMENT &apos;Null when Binary/Annotation.endpoint is null, or no IPv6 address&apos;, `endpoint_port` SMALLINT COMMENT &apos;Null when Binary/Annotation.endpoint is null&apos;, `endpoint_service_name` VARCHAR(255) COMMENT &apos;Null when Binary/Annotation.endpoint is null&apos;) ENGINE=InnoDB ROW_FORMAT=COMPRESSED CHARACTER SET=utf8 COLLATE utf8_general_ci;ALTER TABLE zipkin_annotations ADD UNIQUE KEY(`trace_id_high`, `trace_id`, `span_id`, `a_key`, `a_timestamp`) COMMENT &apos;Ignore insert on duplicate&apos;;ALTER TABLE zipkin_annotations ADD INDEX(`trace_id_high`, `trace_id`, `span_id`) COMMENT &apos;for joining with zipkin_spans&apos;;ALTER TABLE zipkin_annotations ADD INDEX(`trace_id_high`, `trace_id`) COMMENT &apos;for getTraces/ByIds&apos;;ALTER TABLE zipkin_annotations ADD INDEX(`endpoint_service_name`) COMMENT &apos;for getTraces and getServiceNames&apos;;ALTER TABLE zipkin_annotations ADD INDEX(`a_type`) COMMENT &apos;for getTraces&apos;;ALTER TABLE zipkin_annotations ADD INDEX(`a_key`) COMMENT &apos;for getTraces&apos;;ALTER TABLE zipkin_annotations ADD INDEX(`trace_id`, `span_id`, `a_key`) COMMENT &apos;for dependencies job&apos;;CREATE TABLE IF NOT EXISTS zipkin_dependencies ( `day` DATE NOT NULL, `parent` VARCHAR(255) NOT NULL, `child` VARCHAR(255) NOT NULL, `call_count` BIGINT, `error_count` BIGINT) ENGINE=InnoDB ROW_FORMAT=COMPRESSED CHARACTER SET=utf8 COLLATE utf8_general_ci;ALTER TABLE zipkin_dependencies ADD UNIQUE KEY(`day`, `parent`, `child`); 以mysql为存储方式启动(222为另外一台机器)： 1STORAGE_TYPE=mysql MYSQL_HOST=192.168.50.222 MYSQL_TCP_PORT=3306 MYSQL_DB=zipkin MYSQL_USER=root MYSQL_PASS=&apos;root&apos; java -jar zipkin-server-2.11.7-exec.jar 1234567891011121314151617181920Database changedmysql&gt; show tables;+---------------------+| Tables_in_zipkin |+---------------------+| zipkin_annotations || zipkin_dependencies || zipkin_spans |+---------------------+3 rows in set (0.00 sec)mysql&gt; select * from zipkin_spans;+---------------+------------------+------------------+--------------+------------------+-------+------------------+----------+| trace_id_high | trace_id | id | name | parent_id | debug | start_ts | duration |+---------------+------------------+------------------+--------------+------------------+-------+------------------+----------+| 0 | 1540542210608961 | 1540542210608963 | /method_of_a | NULL | | 1540542210608963 | 380025 || 0 | 1540542210608961 | 1540542210608964 | /method_of_b | 1540542210608963 | | 1540542210608968 | 229175 || 0 | 1540542210608961 | 1540542210838146 | mysql.user | 1540542210608963 | | 1540542210838148 | 100442 |+---------------+------------------+------------------+--------------+------------------+-------+------------------+----------+3 rows in set (0.00 sec) 与下图匹配 更形象化的例子 与下图匹配 1. 在10ms的时候，client send发起一个请求 2. 服务端在9ms后(10+9),之后，收到这个请求 server receive 3. 12ms后，server处理完了业务逻辑，返回给客户端 server send 4. 1ms后，client收到了这个响应 client receive 实战代码 new trace是一个span的名称，这三个span是同级别12345678910111213141516171819202122232425262728293031$span_root = $tracer-&gt;newTrace(); $span_root = $tracer-&gt;newTrace(); $span_root-&gt;setName(&apos;pre_con_redis&apos;); $span_root-&gt;start(); try &#123; //1000毫秒 =1秒=1000000微秒 usleep 单位是微妙 usleep(1000000); &#125; finally &#123; $span_root-&gt;finish(); &#125; //new trace是一个span的名称 $span_root_2 = $tracer-&gt;newTrace(); $span_root_2-&gt;setName(&apos;do_redis&apos;); $span_root_2-&gt;start(); try &#123; //1000毫秒 =1秒=1000000微秒 usleep 单位是微妙 usleep(2000000); &#125; finally &#123; $span_root_2-&gt;finish(); &#125; $span_root_3 = $tracer-&gt;newTrace(); $span_root_3-&gt;setName(&apos;do_redis&apos;); $span_root_3-&gt;start(); try &#123; //1000毫秒 =1秒=1000000微秒 usleep 单位是微妙 usleep(3000000); &#125; finally &#123; $span_root_3-&gt;finish(); &#125; 对应下面的1s，2s，3s 父子关系 123456789101112131415161718192021222324252627282930313233343536373839404142434445 $span_root = $tracer-&gt;newTrace(); $span_root-&gt;setName(&apos;php_demo_begin&apos;); $span_root-&gt;start();// $span_root-&gt;tag(&apos;http.status_code&apos;, &apos;200&apos;); $span_root-&gt;tag(&apos;http.status_code&apos;, &apos;200&apos;); try &#123; $parentContext = $span_root-&gt;getContext(); $child_span1=$tracer-&gt;newChild($parentContext); $child_span1-&gt;setName(&quot;pre_con_redis&quot;); $child_span1-&gt;start(); //1000毫秒 =1秒=1000000微秒 usleep 单位是微妙 usleep(1000000); &#125; finally &#123; $child_span1-&gt;finish(); &#125; /**new trace是一个span的名称 *在每个节点处（span）打点，初始化时设置context上下文（暂时忽略这个概念），name（span名称） *这样就产生了一条span记录，包含：context，span-name，start-time，end-time。 **/ $child_span1 = $tracer-&gt;newChild($parentContext); $child_span1-&gt;setName(&apos;do_redis&apos;); $child_span1-&gt;start();// $span_root-&gt;tag(&apos;http.status_code&apos;, &apos;200&apos;); $span_root-&gt;tag(&apos;http.status_code&apos;, &apos;200&apos;); try &#123; //1000毫秒 =1秒=1000000微秒 usleep 单位是微妙 usleep(2300000); &#125; finally &#123; $child_span1-&gt;finish(); &#125; $child_span3 = $tracer-&gt;newChild($parentContext); $child_span3-&gt;setName(&apos;redis_return&apos;); $child_span3-&gt;start();// $span_root-&gt;tag(&apos;http.status_code&apos;, &apos;200&apos;); $span_root-&gt;tag(&apos;http.status_code&apos;, &apos;200&apos;); try &#123; //1000毫秒 =1秒=1000000微秒 usleep 单位是微妙 usleep(1200000); &#125; finally &#123; $child_span3-&gt;finish(); &#125; $span_root-&gt;finish(); 实现截图001 002 003 004 实际问题 如果做到对现有代码的低侵入对中间件、类库的二次包装？ 如果兼顾代码执行效率、性能、稳定性根据load动态调整？ 扩展及降级怎么最方便 该记录什么信息？怎么记录？hook 和ELK结合 和ELK结合 如果图片无法加载，请点此查看完整多图]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>traceing</tag>
        <tag>zipkin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker容器技术与简介]]></title>
    <url>%2F2018%2F06%2F29%2Fdocker-one-01%2F</url>
    <content type="text"><![CDATA[容器技术与docker docker能做什么 简化配置（所有打包到容器里） 提升开发效率（环境相同，统一部署） 隔离应用 容器应用代表 docker and docker swarm docker cloud &amp; docker 企业版（收费） kubernetes k8s（容器编排工具，见下图） 容器技术与dockerdocker能做什么 简化配置（所有打包到容器里） 提升开发效率（环境相同，统一部署） 隔离应用 容器应用代表- docker and docker swarm - docker cloud &amp; docker 企业版（收费） - kubernetes k8s（容器编排工具，见下图） devops 文化+过程+工具 持续 集成 发布 测试 监控 改进 自动化 部署 监控 版本管理 信任和尊重、敏捷的目标、开放的沟通 总览（见下图） - 容器技术概述 传统模式 硬件不兼容、部署复杂 虚拟机模式 hypervisor，可以实现物理资源的自定义调度资源池 容器技术产生背景（环境各种各样、部署、监控各种各样）（见下图） 容器解决了什么问题（解决开发、运维、测试的沟通，见下图） 容器解决了什么问题（解决开发、运维、测试的沟通，见下图） 容器定义 对软件和依赖的标准化打包 实现应用之间的隔离 共享同一个os 容器与虚拟机主要区别 容器是app层面的隔离，base os on docker 虚拟化是物理资源层面的隔离 当然两者可以一起使用 docker魅力（部署wordpress） 依赖 build 镜像 dockder compose up vagrant labs 完]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C根据标准输入解析为json]]></title>
    <url>%2F2017%2F11%2F26%2Fhead_first_c_106%2F</url>
    <content type="text"><![CDATA[知识点：标准输入读入以及scanf返回值及其参数的使用 原书版本123456789101112131415161718192021222324252627// volvo1.cpp: 定义控制台应用程序的入口点。#include "stdafx.h"#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;//head frist c page 106int main() &#123; float latitude; float longitude; char info[80]; int started = 0; puts("data=["); while (scanf("%f,%f,%79[^\n]", &amp;latitude, &amp;longitude, info) == 3) &#123; if (started) &#123; printf(",\n"); &#125; else &#123; started = 1; &#125; printf("&#123;latitude: %f, longitude: %f, info: '%s'&#125;", latitude, longitude, info); &#125; puts("\n]"); return 0;&#125; 结果：12345678data=[12321.123,21321.123,asdffd&#123;latitude: 12321.123047, longitude: 21321.123047, info: &apos;asdffd&apos;&#125;12312.12,213123.213,sdafsdf,&#123;latitude: 12312.120117, longitude: 213123.218750, info: &apos;sdafsdf&apos;&#125;^D]请按任意键继续. . . 我的版本：1234567891011121314151617181920212223242526272829// volvo1.cpp: 定义控制台应用程序的入口点。#include "stdafx.h"#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;//head frist c page 106int main() &#123; char name[40]; char album[40]; int year; char comments[90]; int startd = 0; puts("data=["); while (scanf("%[^,], %[^,], %i, %89[^\n]", name, album, &amp;year, comments) == 4) &#123; if (startd) &#123; printf("，\n"); &#125; else &#123; startd = 1; &#125; printf("&#123;歌曲名称:'%s', 所属专辑：'%s',出品日期:%i，歌词: '%s'&#125;", name, album, year, comments); &#125; puts("\n]"); return 0;&#125; 结果：12345678910111213data=[简单爱,范特西,2012,我想就这样...&#123;歌曲名称:&apos;简单爱&apos;, 所属专辑：&apos;范特西&apos;,出品日期:2012，歌词: &apos;我想就这样...&apos;&#125;简单爱,范特西,2012,我想就这样...，&#123;歌曲名称:&apos;简单爱&apos;, 所属专辑：&apos;范特西&apos;,出品日期:2012，歌词: &apos;我想就这样...&apos;&#125;简单爱,范特西,2012,我想就这样...，&#123;歌曲名称:&apos;简单爱&apos;, 所属专辑：&apos;范特西&apos;,出品日期:2012，歌词: &apos;我想就这样...&apos;&#125;,,]请按任意键继续. . . 结论：scanf参数真多。。先体会体会~ 12345678910111213#include &lt;stdio.h&gt; bool skip()&#123; scanf("%*[^0-9]"); return true; &#125; int main() &#123; int n; while(skip() &amp;&amp; scanf("%d", &amp;n)!=EOF) printf("%d\n", n); return 0; &#125;]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>HEAD_FIRST_C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycncart email设置]]></title>
    <url>%2F2017%2F11%2F25%2Fmycnart_email_config%2F</url>
    <content type="text"><![CDATA[知识点：查看log提交订单时，出现服务器500错误，但是php的相关报错都已经打开。想了一会，还是看fpm_error.log和nginx errorlog 果真，root@tuan:/var/log/nginx# tail -f error.log nginx log 如下 12345.../php7.0-fpm.sock:&quot;, host: &quot;www.maipingzheng.com&quot;, referrer: &quot;http://www.maipingzheng.com/index.php?route=checkout/checkout&quot;2017/11/25 19:50:49 [error] 6104#6104: *504 FastCGI sent in stderr: &quot;PHP message: PHP Fatal error: Uncaught Exception: Error: EHLO not accepted from server! in /usr/share/nginx/cart_2.0.0.3/system/library/mail/smtp.php:120Stack trace:... 重点是EHLO not acceptedfromserver!，追了下代码发现原来是源自于smtp的错误，由于发送邮箱用的是腾讯的企业邮箱，而smtp.php没有涉及到ssl相关。 解决办法smtp服务器由smtp.exmail.qq.com改为 ssl://smtp.exmail.qq.com 备忘~opencart nginx url seo 配置1234567891011121314151617181920server &#123; location / &#123; try_files $uri @opencart; &#125; location @opencart &#123; rewrite ^/(.+)$ /index.php?_route_=$1 last; &#125; location ~* (\.(tpl|ini))$ &#123; deny all; &#125;]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>mycnart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言str_reverse实例]]></title>
    <url>%2F2017%2F11%2F25%2Fhead_firstc_str_reverse_98%2F</url>
    <content type="text"><![CDATA[知识点：字符数组的字符串指针反转 12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;//head frist c page 98void print_reverse(char *s) &#123; size_t len = strlen(s); //指针相加，t为s对应指针的最后一个 char *t = s + len - 1; //最后一个肯定大于第一个s指针指向的位置， while (t &gt;= s) &#123; printf("%c",*t); t = t - 1; &#125; //puts("") 类似于printf("%s\n",s);pust在字符末尾会自动输出一个回车符 puts("我隔开了"); puts ("");&#125;int main()&#123; char letter[] = "abcd"; print_reverse(letter); return 0;&#125; 结果：123dcba我隔开了请按任意键继续. . .]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>HEAD_FIRST_C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言STRSTR实例]]></title>
    <url>%2F2017%2F11%2F25%2Fhead_firstc_strstr_94%2F</url>
    <content type="text"><![CDATA[知识点：strstr()函数会在第一个字符串中查找第二个字符串，如果找到，他会返回第二个字符串在存储器中的位置。 1234567891011121314151617181920212223242526272829303132333435363738#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;//head frist c page 94char tracks [][80] = &#123; "给我一首歌的时间", "七里香", "威廉古堡", "简单爱", "东风破", "叶惠美",&#125;;void find_track(char search_for[]) &#123; int i; for (i = 0; i &lt; 6; i++) &#123; if (strstr(tracks[i], search_for)) &#123; printf("find track %i:%s\n", i,tracks[i]); &#125;else&#123; // printf("your search is %s,not in %s\n",search_for,tracks[i]); &#125; &#125;&#125;int main()&#123; char search_for[80]; printf("search for :"); fgets(search_for, 80, stdin); //由于fgets接收有换行符号+\0，所以把换行符换成结束符 search_for[strlen(search_for)-1]='\0'; find_track(search_for); return 0; &#125; 结果：123search for :爱find track 3:简单爱请按任意键继续. . .]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>HEAD_FIRST_C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis竟态与争抢唯一]]></title>
    <url>%2F2017%2F11%2F22%2Fredis_incr_hash%2F</url>
    <content type="text"><![CDATA[incr比如北京车牌采取先抢到后审批资质的流程。车牌池子中有N多号码，页面呈现以一页十条的方式展示，每个号码后有一个抢的按钮，且一个人只能抢一个车牌，同样一个车牌只能被一个人抢到。业务模型参考 12345678910111213 if ($this-&gt;redis_db-&gt;incr(&quot;bj_&quot;.$car_no) != 1) &#123; 让别人先下手了,点别的去~ &#125;else&#123; //抢到竞态条件，如果不复核资质要求退出，并清除incr if(抢到了但是没资质等)&#123; 释放对此id的竟态权，别占茅坑 $this-&gt;yredis_db-&gt;del(&quot;bj_&quot;.$id); &#125;else&#123; 其他业务A 抱得号码归... 其他业务B &#125;&#125; 另外，incr对string类型，hash类型，sortedSet类型都可以进行操作 blpopblpop相对于lpop有一个好处，可以对多个队列进行优先级操作。blpop会按照key的排列顺序依次弹出，返回值为key的listname及具体元素值，而且可以设置block时间，原则是先阻塞先服务. 123$date = date(&apos;Ymd&apos;, time());//左进左出 ，优先分配一般的车牌号码，然后在分配非常好的连号号码，设置一个阻塞时间return $this-&gt;redis-&gt;blpop(self::$_config[&apos;dispatch_normal_list&apos;] . $date, self::$_config[&apos;dispatch_better_list&apos;] . $date, self::$_config[&apos;redis_block_l_pop_time_out&apos;]); hsetnx设置hash中一个field为指定value，前提是field不存在。如果存在，返回0。这样能保证在一个人只能抢一个车牌，但是抢到车牌执行付款或者其他业务操作过程中，其他人无法对此操作，（即不能将此车牌绑定到其他人身上）。根据具体业务情况，可设置基于car_no的hash field和基于 people 的hash field。hash_base_people {“zhangsan”:”京A888”,”lisi”:”京A999”}hash_base_car_no {“京A888”:”zhangsan”,”京A999”:”lisi”}基于这两个hash 可以做更多关于业务的操作,比如通过hget等查看具体的绑定关系。 hdel有了通过hsetnx的绑定模型，当某个人对某个车牌交付了订金等一系列之后，就代表可以永远的将其消除，这样会用到hdel。另外如果在指定时间内没有做比如交付订金之类的操作，这个车牌号码会回炉到原始列表中。 12345//删除以people_id为key的hash$base_people_id_del = $this-&gt;redis-&gt;hdel(self::$_config[&apos;hash_base_people&apos;], $people_id);//删除以car_no为key的hash$base_car_no_del = $this-&gt;redis-&gt;hdel(self::$_config[&apos;hash_base_car_no&apos;], $clue_id); lpush如果有入口将北京可以抢拍的车牌放入到一个list里 1$lpush_res = $redisObj-&gt;lpush($list_name, $car_no); 其中list_name的值可以根据car_no的具体值来确定，比如有６和８的我就放入到better_car_no列表里，其他的放入到normal_car_no列表里，最后可以用blpop来指定一个先后优先级。 rpoplpush安全的队列弹出模式，比如N多人对一个入口按钮进行操作，如果list结构中有足够的数据，每个人有且只有一条数据会被领取，领取之后再做其他的业务操作。但是问题是，如果用lpop之后，原队列中已被弹出，如果中途客户端在取得该pop的元素后，且完成处理此元素前，客户端发生崩溃。这时候此条消息就凭空消失了。如果没有其他补助措施（比如通过绑定或者记录此弹出的元素）需要严谨要求，可以用rpoplpush可以解决此问题。在客户端真正处理完此pop的元素之后，通过lrem将此消息安全删除。]]></content>
      <categories>
        <category>REDIS</category>
      </categories>
      <tags>
        <tag>REDIS应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符指针与字符数组]]></title>
    <url>%2F2017%2F11%2F20%2Fhead_frist_c_78%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718int main()&#123; char masked_raider[] = "Alived"; char *jimmy = masked_raider; printf("masked_raider is %s,jimmy is %s\n", masked_raider, jimmy); masked_raider[0] = 'd'; masked_raider[1] = 'e'; masked_raider[2] = 'a'; masked_raider[3] = 'd'; masked_raider[4] = 'e'; masked_raider[5] = 'd'; printf("masked_raider is %s,jimmy is %s\n", masked_raider, jimmy); return 0;&#125; 知识点：jimmy和masked_raider 是一个存储器地址的两个别名 字符串字面值保存在只读存储器中 如果要修改字符串，需要在新的数组中创建副本 char masked_raider[] = &quot;Alived&quot;; 程序会在栈上创建一个maskd_raider的数组，并把右值设置为 Alived char *jimmy =&quot;Alived&quot;; 程序会把常量值放在常量存储区，常量存储期是只读的。 接着在栈上创建了jimmy变量，是局部变量 然后把栈上的jimmy变量设置为alived的地址 const char *jimmy = &quot;Alived&quot;; jimmy[0] = &apos;d&apos; 因为常量存储区是只读的，所以用jimmy[0]=&apos;d&apos;的时候，会报错，jimmy为不可修改的左值]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>HEAD_FIRST_C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php捕获fatal error]]></title>
    <url>%2F2017%2F11%2F17%2Fphp-catch-fatel-error%2F</url>
    <content type="text"><![CDATA[用到laravel定时任务的时候，由于类似conf配置问题，无法捕捉到错误，采取的方式如下 1234567891011121314151617181920212223&lt;?phpfunction fatal_handler() &#123; $errfile = "unknown file"; $errstr = "shutdown"; $errno = E_CORE_ERROR; $errline = 0; $error = error_get_last(); if($error)&#123; //发送邮件队列也可以 file_put_contents('./testerror11.txt', json_encode($error)); &#125;&#125;register_shutdown_function("fatal_handler");try&#123; $db=new db();&#125;catch(Exception $e)&#123;echo $e-&gt;error_msg();&#125;]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>异常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符数组+1与指针+1]]></title>
    <url>%2F2017%2F11%2F04%2Fhead_first_c_%2F</url>
    <content type="text"><![CDATA[字符数组+1代码123456789101112131415161718192021#include &lt;stdio.h&gt;int main()&#123; char mystr[]="Abcef"; printf("size of mystr=%i\n",sizeof(mystr)); printf("mystr[0]，他的值为%c:\n",mystr[0]); printf("&amp;mystr[0]，他的内存地址值为%i:\n",&amp;mystr); printf("mystr[1]，他的值为%c:\n",mystr[1]); printf("&amp;mystr[1]，他的内存地址值为%i:\n",&amp;mystr+1); printf("mystr[2]，他的值为%c:\n",mystr[2]); printf("&amp;mystr[2]，他的内存地址值为%i:\n",&amp;mystr+2); printf("mystr[3]，他的值为%c:\n",mystr[3]); printf("&amp;mystr[3]，他的内存地址值为%i:\n",&amp;mystr+3); return 0;&#125; 字符数组+1代码 结果12345678910size of mystr=6mystr[0]，他的值为A:&amp;mystr[0]，他的内存地址值为1703736:mystr[1]，他的值为b:&amp;mystr[1]，他的内存地址值为1703742:mystr[2]，他的值为c:&amp;mystr[2]，他的内存地址值为1703748:mystr[3]，他的值为e:&amp;mystr[3]，他的内存地址值为1703754:Press any key to continue 指针+1代码12345678910111213141516#include &lt;stdio.h&gt;int main()&#123; char *mystr="ABC"; printf("size of mystr=%i\n",sizeof(mystr)); printf("mystr[0]，他的值为%c:\n",mystr[0]); printf("&amp;mystr[0]，他的内存地址值为%i:\n",&amp;mystr); printf("mystr[1]，他的值为%c:\n",mystr[1]); printf("&amp;mystr[1]，他的内存地址值为%i:\n",&amp;mystr+1); printf("mystr[2]，他的值为%c:\n",mystr[2]); printf("&amp;mystr[2]，他的内存地址值为%i:\n",&amp;mystr+2); printf("mystr[3]，他的值为%c:\n",mystr[3]); printf("&amp;mystr[3]，他的内存地址值为%i:\n",&amp;mystr+3); return 0;&#125; 指针+1代码 结果12345678size of mystr=4mystr[0]，他的值为A:&amp;mystr[0]，他的内存地址值为1703740:mystr[1]，他的值为B:&amp;mystr[1]，他的内存地址值为1703744:mystr[2]，他的值为C:&amp;mystr[2]，他的内存地址值为1703748:mystr[3]，他的值为 结论：指针的+1，只对当前指针所占字节数的+1字符数组的+1，是对当前数组指针的sizeof+1]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>数组与指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机科学CS分类]]></title>
    <url>%2F2017%2F11%2F04%2Fcomputer-science-summary%2F</url>
    <content type="text"><![CDATA[经常看到CS这个词，今天偶然下载了知乎刘洋的电子书。再此也敲一下。 理论计算机科学数据结构和算法计算理论信息论与编码理论编程语言与编译器形式化方法 计算机系统计算机体系结构与计算机工程操作系统并发、并行与分布式系统计算机网络计算机安全密码学数据库计算机应用技术计算机图形学科学计算多媒体技术数据挖掘软件工程人工智能自助推理机器学习计算机视觉自然语言处理]]></content>
      <categories>
        <category>computer</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[根据当前日期算出N个工作日之后的日期]]></title>
    <url>%2F2017%2F05%2F31%2Fworkday%2F</url>
    <content type="text"><![CDATA[需求：给定一个日期，要求算出N天（工作日）后的日期 直接上代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160 &lt;?php//节假日 需要手动维护配置文件或者放入db中 $holiday=[ &apos;2017-04-29&apos;, &apos;2017-04-30&apos;, &apos;2017-05-01&apos;, &apos;2017-05-06&apos;, &apos;2017-05-07&apos;, &apos;2017-05-13&apos;, &apos;2017-05-14&apos;, &apos;2017-05-20&apos;, &apos;2017-05-21&apos;, &apos;2017-05-28&apos;, &apos;2017-05-29&apos;, &apos;2017-05-30&apos;, &apos;2017-06-03&apos;, &apos;2017-06-04&apos;, &apos;2017-06-10&apos;, &apos;2017-06-11&apos;, &apos;2017-06-17&apos;, &apos;2017-06-18&apos;, &apos;2017-06-24&apos;, &apos;2017-06-25&apos;, &apos;2017-07-01&apos;, &apos;2017-07-02&apos;, &apos;2017-07-08&apos;, &apos;2017-07-09&apos;, &apos;2017-07-15&apos;, &apos;2017-07-16&apos;, &apos;2017-07-22&apos;, &apos;2017-07-23&apos;, &apos;2017-07-29&apos;, &apos;2017-07-30&apos;, &apos;2017-08-05&apos;, &apos;2017-08-06&apos;, &apos;2017-08-12&apos;, &apos;2017-08-13&apos;, &apos;2017-08-19&apos;, &apos;2017-08-20&apos;, &apos;2017-08-26&apos;, &apos;2017-08-27&apos;, &apos;2017-09-02&apos;, &apos;2017-09-03&apos;, &apos;2017-09-09&apos;, &apos;2017-09-10&apos;, &apos;2017-09-16&apos;, &apos;2017-09-17&apos;, &apos;2017-09-23&apos;, &apos;2017-09-24&apos;, &apos;2017-10-01&apos;, &apos;2017-10-02&apos;, &apos;2017-10-03&apos;, &apos;2017-10-04&apos;, &apos;2017-10-05&apos;, &apos;2017-10-06&apos;, &apos;2017-10-07&apos;, &apos;2017-10-08&apos;, &apos;2017-10-14&apos;, &apos;2017-10-15&apos;, &apos;2017-10-21&apos;, &apos;2017-10-22&apos;, &apos;2017-10-28&apos;, &apos;2017-10-29&apos;, &apos;2017-11-04&apos;, &apos;2017-11-05&apos;, &apos;2017-11-11&apos;, &apos;2017-11-12&apos;, &apos;2017-11-18&apos;, &apos;2017-11-19&apos;, &apos;2017-11-25&apos;, &apos;2017-11-26&apos;, &apos;2017-12-02&apos;, &apos;2017-12-03&apos;, &apos;2017-12-09&apos;, &apos;2017-12-10&apos;, &apos;2017-12-16&apos;, &apos;2017-12-17&apos;, &apos;2017-12-23&apos;, &apos;2017-12-24&apos;, &apos;2017-12-30&apos;, &apos;2017-12-31&apos;, //... ]; function afterWorkDay($start_timestamp=&apos;&apos;,$add_workday_num=&apos;&apos;,$holiday=[])&#123; // 如果加天数的的时候遇到休假日，则代表需要额外增加的天数 $extra_day=0; //已经实际增加的天数的数量 $workday_added_num=0; for($i=1;$i&lt;=$add_workday_num;$i++)&#123; $detail_time=date(&apos;Y-m-d H:i:s&apos;,($start_timestamp)+$i*(60*60*24)); $workday_added_num++; //只取宽泛的月日就好 $wide_date=date(&apos;Y-m-d&apos;,strtotime($detail_time)); // 如果其中一天在holiday中 if(in_array($wide_date, $holiday))&#123; //取消已经增加的天数，后面再继续加上 $workday_added_num--; // 需要额外增加的天数 $extra_day++; &#125; //如果加完之后的日期的下一天还是休息日，需要再次增加额外增加天数 $extra_judge=date(&quot;Y-m-d&quot;,strtotime($wide_date)+86400); &#125; //如果需要增加的天数与实际已经增加的天数不相等 if($add_workday_num!=$workday_added_num)&#123; while (in_array($extra_judge, $holiday)) &#123; $extra_day++; $extra_judge=date(&quot;Y-m-d&quot;,strtotime($extra_judge)+86400); &#125; &#125; //实际应增加总天数=已经增加天数+（应增加天数-已经增加天数）+额外需要增加天数 $add=$workday_added_num+($add_workday_num-$workday_added_num)+$extra_day; return date(&apos;Y-m-d H:i:s&apos;,($start_timestamp)+$add*(60*60*24)); // $result_date=date(&apos;Y-m-d&apos;,($start_timestamp)+$add*(60*60*24)); // 如果这个结果也是在假期日内 // while (in_array($result_date, $holiday)) &#123; // $result_date=date(&apos;Y-m-d&apos;,strtotime($result) +86400); // $result=date(&apos;Y-m-d H:i:s&apos;,strtotime($result) +86400); // &#125; &#125;// xx发起时间 6月1日是周四， $time=mktime(&apos;13&apos;,&apos;30&apos;,&apos;56&apos;,&apos;06&apos;,&apos;01&apos;,&apos;2017&apos;); $start_timestamp=$time; // var_dump($start_timestamp);//计算两个工作日后的时间 echo afterWorkDay($start_timestamp,2,$holiday);//out put 2017-06-05 13:30:56 2017国务院放假权威安排]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>工作日计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP-CAHCE中的CACHE-CONTROL、Etag、Modify]]></title>
    <url>%2F2017%2F03%2F07%2Fhttp-cache%2F</url>
    <content type="text"><![CDATA[用世界上最好的语言演示一下etag123456789101112131415&lt;?php// apache 服务器，如果您是nginx请自行配置读取header等信息，同时下面会有nginx测试$file = &apos;etag.txt&apos;;$etag = md5_file($file);$headers = apache_request_headers();if (isset($headers[&apos;If-None-Match&apos;]) &amp;&amp; trim($headers[&quot;If-None-Match&quot;]) == $etag) &#123; header(&quot;HTTP/1.1 304 Not Modified&quot;);&#125; else &#123; $content = file_get_contents($file); header(&quot;Etag: $etag&quot;); echo $content;&#125; 第一次请求，服务器返回200.我分别列下请求头【RequsetHeaders】和响应头【ResponseHeaders】 请求头123456789Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Accept-Encoding:gzip, deflate, sdchAccept-Language:zh-CN,zh;q=0.8,en;q=0.6Cache-Control:no-cacheConnection:keep-aliveHost:kache.comPragma:no-cacheUpgrade-Insecure-Requests:1User-Agent:Mozilla/5. 响应头 12345678910111213Request URL:http://kache.com/etag.phpRequest Method:GETStatus Code:200 OKRemote Address:127.0.0.1:80Connection:Keep-AliveContent-Type:text/htmlDate:Tue, 07 Mar 2017 13:02:13 GMTEtag:966aa4bd5183fd9358fd222647c5c6a3Keep-Alive:timeout=5, max=99Server:Apache/2.4.10 (Win32) OpenSSL/0.9.8zb mod_fcgid/2.3.9Transfer-Encoding:chunkedX-Powered-By:PHP/5.4.33 需要注意第一次请求头没有If-None-Match:，注意第一次响应头有Etag:这个标签,注意第一次是200 第二次请求 请求头： 123456789Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Accept-Encoding:gzip, deflate, sdchAccept-Language:zh-CN,zh;q=0.8,en;q=0.6Cache-Control:max-age=0Connection:keep-aliveHost:kache.comIf-None-Match:966aa4bd5183fd9358fd222647c5c6a3Upgrade-Insecure-Requests:1User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36 响应头: 123456789Request URL:http://kache.com/etag.phpRequest Method:GETStatus Code:304 Not ModifiedRemote Address:127.0.0.1:80Connection:Keep-AliveDate:Tue, 07 Mar 2017 13:02:16 GMTKeep-Alive:timeout=5, max=98Server:Apache/2.4.10 (Win32) OpenSSL/0.9.8zb mod_fcgid/2.3.9 需要注意第二次请求头有If-None-Match:，注意第二次响应为304 再用php语言演示一下Last-Modified123456789101112131415161718&lt;?php/** *If-Modified-Since[request] &amp; Last-Modified [response] *减少网络字节传输 */$headers = apache_request_headers();$file = &apos;modified.txt&apos;;if (isset($headers[&apos;If-Modified-Since&apos;]) &amp;&amp; (strtotime($headers[&apos;If-Modified-Since&apos;]) == filemtime($file))) &#123; header(&apos;Last-Modified: &apos; . gmdate(&apos;D, d M Y H:i:s&apos;, filemtime($file)) . &apos; GMT&apos;, true, 304);&#125; else &#123; header(&apos;Last-Modified: &apos; . gmdate(&apos;D, d M Y H:i:s&apos;, filemtime($file)) . &apos; GMT&apos;, true, 200); $content = file_get_contents($file); echo $content;&#125; If-Modified-Since[请求头的] 和 Last-Modified [响应头的]这一对关系的HADER头我这里就不贴了。稍后的ppt里有比较详细的说明 我们常用的就是Last-Modified和Etag一起来用，上php代码12345678910111213141516171819202122232425&lt;?php$file=&apos;etag_modify.txt&apos;;$last_modified_time=filemtime($file);$etag = md5_file($file);$headers = apache_request_headers();if (@strtotime($headers[&apos;If-Modified-Since&apos;]) == $last_modified_time || @trim($headers[&apos;If-None-Match&apos;]) == $etag) &#123; header(&apos;Content-Length: &apos;.filesize($file)); header(&quot;HTTP/1.1 304 Not Modified&quot;);&#125;else&#123; header(&quot;Etag: $etag&quot;); header(&apos;Last-Modified: &apos;.gmdate(&apos;D, d M Y H:i:s&apos;, $last_modified_time).&apos; GMT&apos;, true, 200); header(&apos;Content-Length: &apos;.filesize($file)); $content=file_get_contents($file); echo $content;&#125; 这样做的好处是双重验证，同时满足两者条件才会缓存失效，弥补了modify的粒度最多为秒的问题以及modify的打开关闭即更改时间的问题。当然etag也会有坑，不同物理机可能会导致相同文件不同结果（没实验过） 直接上NGINX配置示例毕竟php做服务端水平有限，大家可以参考 swoole framework OR workerman中对etag和modify的处理。 不多说，上NGINX配置段，为了演示modify ，可以在/etc/nginx/nginx.conf中把etag关闭 1234567http &#123; ## # Basic Settings ## etag off; ... 关于其他静态文件缓存的设置 123456location ~* \.(?:css)$ &#123; #expires 1y; add_header Cache-Control max-age=5; add_header Cache-Control &quot;public&quot;; add_header Last-Modified &quot;&quot;;&#125; 简单对以上括号内代码说明： expires 1y; 是http协议1.0写法，1.1对应的是cache-contorl:max-age=’’;前者为GMT绝对时间，后者为相对时间。 add_header Cache-Control max-age=5; 缓存5秒，如果没有Last-Modified（即设置了 add_header Last-Modified “”;） ，期间会一直直接请求服务器，服务器一直返回200，如果有设置Last-Modified，5秒后会请求一次服务器，5秒前会返回304. 简单归纳Last-Modified和max-age（expires）关系 如果设置了max-age=0，而没有启用modify，那么不会缓存 如果单单启用modify，而没有max-age==0.也会缓存 如果启用了modify，并且 max-age=0，那么不会缓存 如果设置了max-age=1000，但没有启用modify ，不会缓存 再此说明上面配置导致的结果：5秒内如果文件有变化，那么客户端不会有任何感知。5秒后将会重新发起请求，得到200响应。然后再缓存5秒【注意没有开启etag】 下面这个例子和上面一样，是针对图片等，缓存1一个月，即使服务端删除了，1个月内也会正常显示（除非ctrl+f5，或者服务端重启了）public代表任何代理服务器都可以缓存，对应的为private，只允许客户端浏览器缓存。 12345location ~* \.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ &#123; expires 1M; add_header Cache-Control &quot;public&quot;; add_header Last-Modified &quot;&quot;;&#125; 那需要有更改就更新，怎么办？123456location ~* \.(?:css)$ &#123; expires 1y; # add_header Cache-Control max-age=5; # add_header Cache-Control &quot;public&quot;; # add_header Last-Modified &quot;&quot;;&#125; 以上配置虽然过期时间是一年，但是服务端会返回Last-Modified，来确认，意思为你就vim了一下xx.css,即使没有做任何更改，浏览器也会重新发起请求。你要是没改，那八成就一年后见了。 那我就不想缓存怎么办？用cache-control：控制用no-cahce【浏览器端等可以缓存，但是没有什么卵用】用no-store【浏览器端等不用缓存，不用费劲。每次都跟我服务端请求】用must-revalidate，浏览器端别整没用的，到期了就马上跟我请求。麻溜的必须。防止的就是代理服务器等自作聪明，认为没有过期。 1234location ~* \.(?:js)$ &#123; add_header Cache-Control no-cache; add_header Cache-Control must-revalidate;&#125; 测试代码和PPT在这里]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>CACHE</tag>
        <tag>PHP</tag>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在CI框架中加入生成api文档]]></title>
    <url>%2F2017%2F01%2F20%2Fcode-igniter-apidoc%2F</url>
    <content type="text"><![CDATA[先上图文档列表页面-1 文档列表页面-2 文档详情页面 主要是抽取自phalapi使用方法 如果使用默认ci框架及结构目录，只需将Controller/doc.php,views/doc/*的两个模版文件放入项目即可。 如果其他项目引入，只需在Controller/doc.php中指定项目Controller目录，以及对应的文件夹名对应的类名方法即可。 文档注释方法可以参考代码中doc.php中的注释 GITHUB下载地址]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP框架</tag>
        <tag>CI框架</tag>
        <tag>接口文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux top about cpu]]></title>
    <url>%2F2016%2F12%2F07%2Flinux-top-about-cpu%2F</url>
    <content type="text"><![CDATA[1234Tasks: 179 total, 4 running, 175 sleeping, 0 stopped, 0 zombie%Cpu(s): 10.3 us, 1.3 sy, 0.0 ni, 88.5 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem: 3012668 total, 1073356 used, 1939312 free, 52772 buffersKiB Swap: 1308668 total, 0 used, 1308668 free. 409160 cached Mem us 用户态 cpu执行用户进程的时间，包括nice时间，一般用户空间cpu高点比较好 sy 系统 cpu在内核运行时间，包括软硬终中断时间，如果此值较高，说明系统有问题 id idle 系统空闲wa waiting 系统等待io操作所花费的时间，系统不应该花费太多时间在此，如果有，说明io有瓶颈hi hard irq time 硬中断，一般由硬件发出si soft irq time 软中断，由信号发出，程序指令发出，比如等待io请求，一般没有硬件的参与st steal time，被强制等待 虚拟cpu的时间，比如为另一个虚拟处理器服务 以上输出根据 /proc/stat 12345678910tb@tb:~$ cat /proc/statcpu 5803 228 1006 54723 212 0 22 0 0 0cpu0 5803 228 1006 54723 212 0 22 0 0 0intr 105215 41 238 0 0 0 0 0 0 0 0 0 0 288 0 0 741 0 0 0 3170 1912 14235 58 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0ctxt 1172838btime 1481084918processes 2570procs_running 6procs_blocked 0softirq 48007 4 24384 126 3233 14075 0 271 0 0 5914 了解更多]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接口调用安全性]]></title>
    <url>%2F2016%2F12%2F05%2Finterface_security%2F</url>
    <content type="text"><![CDATA[一些接口调用中，为了安全原因，会加入一些token或者是签名。以下是个简单例子：根据post给被调用方的key和value数组，其中先根据数组做ksort，然后对value的值做（递归）拼接得到$string。返回后用key.$string，调用方和被调用方按照此规则，对传递过来的额外post字段中的sign做验证，另外也可以结合一些非对称加密和对称加密，交换固定的字段和值来生成token，（此token也是固定的，可以随着时间等变化来变化），这样达到一定的安全性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344function getSign($data, $key = '')&#123; if(is_array($data))&#123; ksort($data);//按照键值排序 &#125; $string = getPostString($data); return $string; // return md5($string.$key);&#125;/** * 数组系列化成字符串 */function getPostString(&amp;$post)&#123; $string = ''; if(is_array($post)) &#123; foreach($post as $item) &#123; if(is_array($item)) $string .= getPostString($item); else $string .= $item; &#125; &#125; else &#123; $string = $post; &#125; return $string;&#125;$params=['mobile'=&gt;'18618824588','code'=&gt;'114360','hid'=&gt;'2700','name'=&gt;'tb','city_serial_id'=&gt;'bj2700',];var_dump(ksort($params));var_dump($params);echo getSign($params);]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>接口调用</tag>
        <tag>安全性</tag>
        <tag>sign&amp;token</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHPSTORM中给一个方法动态添加注释]]></title>
    <url>%2F2016%2F12%2F05%2Fphpstorm-add-comment-in-function%2F</url>
    <content type="text"><![CDATA[目的：在phpstorm中，动态的给一个方法添加注释先添加一个动态模版【Live Templates】ct==Crate Time 编辑这个动态模版【Live Templates】，并应用（Application）到 PHP Comments，可见图一第五步 最后在注释生成的部分加载这个动态模版 EG123456/** * Desc:看房团热门路线推荐 * v4.1.7新增接口 * @Date&amp;Time 2016-12-01 16:48 * User: TongBo */]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>PHPSTORM</tag>
        <tag>编辑器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在ubuntu上升级到PHP7]]></title>
    <url>%2F2016%2F11%2F21%2Fphp7-update-on-ubuntu%2F</url>
    <content type="text"><![CDATA[卸载旧版本phpapt-get autoremove php* 安装新源123apt-get install software-properties-common、add-apt-repository ppa:ondrej/phpapt-get update 安装新版php 1apt-get install php-common php-cli php-fpm php-mysql php-gd php-dev php-zip php-pear php-curl php-mbstring 一些命令及路径/etc/init.d/php7.0-fpm 中的重启php7.0fpm命令 12root@lyh:/etc/init.d# /etc/init.d/php7.0-fpm status[start stop]php7.0-fpm start/running, process 1704 /etc/php/7.0/fpm/php-fpm.conf中的配置 pid = /run/php/php7.0-fpm.pid /etc/php/7.0/fpm/pool.d/www.conf中的 listen = /run/php/php7.0-fpm.sock /etc/nginx/sites-enabled中的yoursite.conf，和上面路径一致 fastcgi_pass unix:/var/run/php/php7.0-fpm.sock; PHP-v12345root@lyh:/etc/php/7.0/fpm# php -vPHP 7.0.13-1+deb.sury.org~trusty+1 (cli) ( NTS )Copyright (c) 1997-2016 The PHP GroupZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies with Zend OPcache v7.0.13-1+deb.sury.org~trusty+1, Copyright (c) 1999-2016, by Zend Technologies]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP7</tag>
        <tag>FPM</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jp2a把图片转为ascii]]></title>
    <url>%2F2016%2F11%2F21%2Fjp2a-meituan%2F</url>
    <content type="text"><![CDATA[先看效果 再贴代码12345678#!/bin/bashmakejp2a --color --background=light -b -f --term-fit waimai.jpg &gt;waimai.txtcat waimai.txtsleep 2make clean &gt;/dev/null 2&gt;&amp;1jp2a --color --background=light -b -f --term-fit zaiyiqilvse.jpg &gt;zaiyiqi.txtcat zaiyiqi.txt 注意需要先安装jp2a，开头那些编译的效果是在编译一个php的扩展，和本身效果呈现没有关系。就是为了小装b用的上面的sh脚本 和你需要编译的扩展在一起就行。]]></content>
      <categories>
        <category>LINUX</category>
      </categories>
      <tags>
        <tag>jp2a</tag>
        <tag>ascii</tag>
        <tag>meituan</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP_APP_RSA_AES实现服务器客户端双向加密]]></title>
    <url>%2F2016%2F11%2F18%2FPHP-APP-RSA-AES%2F</url>
    <content type="text"><![CDATA[目的：实现和app端的双向加密解密功能共有七个文件其中包括三个类文件 lib_aes.php aes对称加密解密类 server_rsa_crypt.php 服务端RSA公钥私钥非对称加密解密类 client_rsa_crypt.php 客户端RSA公钥私钥非对称加密解密类 四个过程文件,其中文件中有注释和exapmle数据 第一步：客户端和服务端交换密钥（明文）-service_client_exchange.php 第二步:客户端发起带参数请求（加密后）- client_generate_aeskey.php 第三步：服务端解密客户端请求 并加密服务端数据（先解密，后加密）-service_decrypt_client_001.php 第四步：客户端解密服务端数据（先解密，..加密）-client_decrypt_server.php 代码地址And So on…]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>RSA</tag>
        <tag>AES</tag>
        <tag>双向加密解密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA 装饰模式-2016软件设计师下半年考试真题]]></title>
    <url>%2F2016%2F11%2F15%2Fjava-2016-decorator%2F</url>
    <content type="text"><![CDATA[题目要求：打印发票头、内容、底部的要求BTW,八成这次软考又挂了… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Invoice&#123; public void printInvoice()&#123; System.out.println("this is content"); &#125;&#125;class Decorator extends Invoice&#123; protected Invoice ticket; public Decorator (Invoice t)&#123; ticket=t; &#125; public void printInvoice()&#123; if(ticket!=null)&#123; ticket.printInvoice(); &#125; &#125;&#125;class HeaderDecorator extends Decorator&#123; public HeaderDecorator(Invoice t)&#123; super(t); &#125; public void printInvoice()&#123; System.out.println("this is the header"); super.printInvoice(); &#125;&#125;class FooterDecorator extends Decorator&#123; public FooterDecorator(Invoice t)&#123; super(t); &#125; public void printInvoice()&#123; super.printInvoice(); System.out.println("this is the footer"); &#125;&#125;public class zhuangshi &#123; public static void main(String[] args)&#123; Invoice t =new Invoice(); Invoice ticket; ticket=new FooterDecorator(new HeaderDecorator(t)); ticket.printInvoice(); System.out.println("====================="); ticket=new FooterDecorator(new HeaderDecorator(new Decorator(null))); ticket.printInvoice(); &#125;&#125; 这么写也行 ，不知道哪个算标准答案1234567Invoice t =new Invoice(); Invoice ticket; ticket=new HeaderDecorator(new FooterDecorator(t)); ticket.printInvoice(); System.out.println("====================="); ticket=new HeaderDecorator(new FooterDecorator(null)); ticket.printInvoice(); 结果]]></content>
      <tags>
        <tag>装饰模式</tag>
        <tag>软件设计师</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java桥接模式-软件设计师考试2013下半年]]></title>
    <url>%2F2016%2F11%2F11%2Fjava-bridge%2F</url>
    <content type="text"><![CDATA[类图及题目要求 代码可以运行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091interface Drawing&#123; public void drawLine(double x1,double y1,double x2,double y2); public void drawCircle(double x,double y,double r);&#125;class V1Drawing implements Drawing&#123; public void drawLine(double x1,double y1,double x2,double y2)&#123;DP1.draw_a_line(x1,y1,x2,y2);&#125; public void drawCircle(double x,double y,double r)&#123;DP1.draw_a_circle(x, y, r);&#125;&#125;class V2Drawing implements Drawing&#123; public void drawLine(double x1,double x2,double y1,double y2)&#123;DP2.drawLine(x1,y1,x2,y2);&#125; public void drawCircle(double x,double y,double r)&#123;DP2.drawcircle(x, y, r);&#125;&#125;class DP1&#123; static public void draw_a_line(double x1,double y1,double x2,double y2)&#123; System.out.println("DP1 画的线"); &#125; static public void draw_a_circle(double x,double y,double r)&#123; System.out.println("DP1 画的圆"); &#125;&#125;class DP2&#123; static public void drawLine(double x1,double y1,double x2,double y2)&#123; System.out.println("DP2 画的线"); &#125; static public void drawcircle(double x,double y,double r)&#123; System.out.println("DP2 画的圆"); &#125;&#125;abstract class Shape&#123; private Drawing _dp; public Shape(Drawing dp)&#123; this._dp=dp; &#125; abstract public void draw(); public void drawLine(double x1,double y1,double x2,double y2)&#123; this._dp.drawLine(x1,x2,y1,y2); &#125; public void drawCircle(double x,double y,double r)&#123;this._dp.drawCircle(x,y,r);&#125;&#125;class Rectangle extends Shape&#123; private double _x1,_x2,_y1,_y2; public Rectangle(Drawing dp,double x1,double x2,double y1,double y2)&#123; super(dp); this._x1=x1; this._x2=x2; this._y1=y1; this._y2=y2; &#125; public void draw()&#123; System.out.println("画长方形"+this._x1+this._x2+this._y1+this._y2); drawLine(_x1,_x2,_y1,_y2); &#125;&#125;class Circle extends Shape&#123; private double _x,_y,_r; public Circle (Drawing dp,double x,double y,double r)&#123; super(dp); &#125; public void draw()&#123;drawCircle(_x,_y,_r);&#125;&#125;public class qiaojie &#123; public static void main(String[] args)&#123; V1Drawing v1=new V1Drawing(); V2Drawing v2=new V2Drawing(); Rectangle r1=new Rectangle(v1,1.0,2.0,3.0,4.0); r1.draw(); v2.drawCircle(2.1, 4.5, 5.6); v2.drawLine(2.4, 3.3 ,4.2, 5.1); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>软件设计师</tag>
        <tag>JAVA</tag>
        <tag>桥接模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka基本概念应用场景高级特性等]]></title>
    <url>%2F2016%2F11%2F11%2Fkafka-basic-from-imooc%2F</url>
    <content type="text"><![CDATA[大纲 基本概念 消息结构 kafka特点及应用场景 java code demo 高级特性 事务 零拷贝 more… 2-1 来源及作用 来源：linkedin开源：a distributed streamed platform databus cubrect parseq kafkastream platform has three key capabilities 特性 消息队列 mq 数据存储 db 流处理 stream 构建实时流管道，实时处理数据流 real time &amp; transform react 3.面向于数据流的生产、消费、存储、处理 3-1 基本概念物理概念（服务器|| 硬件|| 载体…）逻辑概念（策略 逻辑…） producer消息和数据的生产者，向一个topic发送消息的 进程 代码 服务 consumer消息和数据的消费者，订阅数据topic并且处理器发布的消息的 进程 代码 服务 consumer group 逻辑概念消费组，针对同一个topic，会广播给不同的group，一个group中，只有一个consumer可以消费该消息。 broker 物理概念kafka集群节点之一， topic 逻辑概念kafka消息的类别，对数据进行分类 区分 隔离 partition 物理概念kafka下数据存储的基本单元，一个topic会被分散处理存储到多个partition，每个partition是有序的，但是每个topic无法保证有序。 replication同一个partition可能会有多个raplica，多个replica之间数据时一样的 replication leader多个replication副本之间需要一个且只有一个leader major负责该partition与producer和consumer交互，其他的replication是副本，只负责同步数据。 replica manager负责管理当前broler所有分区和副本的信息，处理kafka controller 发起的请求，副本状态的切换 ，添加 读取消息等，选举出一个replication leader 3-2更多的kafka基本概念 partition 每个topic被切分称多个partitions 消费者的数目小于或者等于partiton的数目每一个消费者会消费一个partition，如果消费者数目大于partition的数量，会出现一个partition被多个消费者消费 broker group中的每一个broker保存topic的一个或多个partition，注意区别对待consumer group，同一个partion不会被保存在相同的broker上。如果partion非常大，可以用多个broker保存，而不是说一个partition被保存了多份在一个broker上。 comsumer group中仅有一个consumer 读取topic的一个或者多个partion，并且是唯一的consumer，一个partition只能被这一个consumer消费，可以参考第二条 为什么要有consumer group为了容错，group有容错机制?为了提高性能？后续再讲 replication 副本当集群中有broker挂了，partition ，系统可以主动使replications提供服务，系统默认每个topic的replication系数为1，可以在创建topic时单独设置 replication基本特点是topic的partition所有的读和写都从followers，follower必须能够及时复制leader数据增加容错性和可扩展性3-3 kafka基本结构![image][1]数据从productor流向consumer，kafka暴露四个接口 connectors api stream processors api producer api consumer apikafka强依赖于zp，broker信息、topic、partition的分布应用包括： hadoop 实时监控 数据仓库 其他… offset 当前消息所处的偏移量 4字节 length 当前消息整体长度 4字节 crc32 校验当前消息完整性 4字节 magic 分布式系统一般都设计为这个字段，固定的一个字段。可以快速的判定是不是kafka的消息。如果不是，则扔掉，不需要经过校验等动作 attributes 放置当前消息属性 1字节 枚举值 timestamp 消费时间戳 8字节 key length 4字节 value 无限制 value length 4字节 value 无限制 3-4 kafka特点 分布式 多分区 partition 多副本 replication 多订阅者topic可以有一个或者多个订阅者，每一个订阅者只能有一个partition 基于zookeeper调度 高性能 高吞吐量 几十万/s 低延迟 高并发 时间复杂度o（1） 持久性和扩展性 数据可持久化 容错性 按组消费 多副本 支持在线水平扩展 增加新机器就可以放topic和partion 消息自动平衡 consumer group 避免消息过于集中在某几台服务器，在服务端和消费者两端自动平衡，怎么实现的？ 3.5 应用环节 消息队列 分区、副本、持久化、稳定、重复消费、低延迟… 行为跟踪 发布订阅模式的扩展应用 在线或者离线应用 元信息监控 运维数据监控 日志收集 elk flume ，kafka可以让日志活起来，低延迟，支持更多的数据源和消费者，脱离以文件为中心的日志收集 流处理 收集上游 处理在下游 对一个topic多次处理后再次处理，分段式链路流处理 事件源 记录状态转移序列 回溯事件变更 存储日志 动态汇总 持久性日志 commit log 日志压缩 通过对日志回溯， 3.5 kafka简单案例 环境启动 下载zookeeper kafka下载 解压、环境变量、配置文件… zookeeper-server-start bin/kafka/-topics –create – zookeeper 127.0.0.1:2181 –replication-factor 1 –partition s 3 –topic imooc-kafka-topic bin/kafka-topics –list –zookeeper 127.0.0.1:2121 隐藏分区 __consumer_offsets 启动producer /bin/kafka-console-producer –broker-list 启动消费者 /bin/kafka-console-comsumer –bootstrap-server 127.0.0.1:9002 –topic imooc-kafka-topic –from-beginning 简单生产者 简单消费者 4-3 kafka代码案例基于java spring bootjava代码真的挺有意思的，比php的好看 有艺术多了 5-1 kafuka高级特性-消息事务 为什么要支持事务 要支持读取-处理-写入模式 ，要保证数据一致性 流处理需求的增加增强 需要更准确的数据处理结果 数据传输事务的定义 最多一次：消息不会被重复发送，最多被传输一次，但也可能一次也不传输 最少一次：消息不会被漏发，最少被传输一次，但可能重复传输。但最好消息方最好幂等操作 精确的一次 exactly once：不会漏也不会重复，仅仅一次，最优美。不会丢失，不会重复。 事务保证 内部重试问题procedure 幂等处理（自身已经处理好） 多分区原子写入读取 -处理-写入 如何实现原子性？也就是说如何保证成功消费（从topic 1）并且发布（到topic2）X为偏移量，会被标记成已消费，并写入到一个内部的kafka的topic（offset topic），记录office commit，此时认为被成功消费（已经提交了偏移量） 事务保证-避免僵尸实例 每个事务producer分配一个transactional.id,在进程重新启动时能够识别相同的producer实例 kafka增加一个与transactional.id的epoch（时期），存储每个transactionalid内部元数据 一旦epoch被触发，任何具有相同transactionalid和更旧的epoch的producer被视为僵尸，kafka会拒绝来自这些来自procedure的后续事务性写入 5-2 kafka高级特性之零拷贝 nginx rocketmq netty kafka都具有实现了这种技术 网络传输持久性日志块（生产和消费的消息） java nio channel.transforTo方法 linux sendfile 系统调用 文件传输到网络的公共数据路径 1.操作系统将数据从磁盘读入到内核空间的页缓存 应用程序将程序从内核空间读入到用户空间内存中 应用程序将数据写回到内核空间的socket缓存中 操作系统将数据从socket缓冲区复制到网卡缓冲区，以便将数据从网络发出 以上为4次拷贝，才能从磁盘到达网卡 零拷贝过程 操作系统将数据从磁盘读入到内核空间的页缓存 将数据的位置和长度的信息的描述符增加至内核空间的socket缓冲区中 操作系统将数据从内核拷贝到网卡缓冲区，以便将数据从网卡发出 此处的零拷贝指的是内核空间和用户空间的交互拷贝为0 文件传输到网络的公共数据路径的演变从 1. CPU发指令给I/O设备的DMA，由DMA将我们磁盘中的数据传输到内核空间的内核buffer。 2. 第二阶段触发我们的CPU中断，CPU开始将将数据从kernel buffer拷贝至我们的应用缓存 3. CPU将数据从应用缓存拷贝到内核中的socket buffer. 4. DMA将数据从socket buffer中的数据拷贝到网卡缓存。 改为NIO 1. 调用sendfie(),CPU下发指令叫DMA将磁盘数据拷贝到内核buffer中。 2. DMA拷贝完成发出中断请求，进行CPU拷贝，拷贝到socketbuffer中，sendFile调用完成返回。 3.DMA将socket buffer拷贝至网卡buffer。 补充-零贝定义： 在计算机在网络上发送文件时候，不需要将文件内容拷贝到用户空间（user space） 而直接在内核空间 （kernel space ）中传输到网络的形式。 [1]: /img/kafka/kafka_basic_construct.png]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>消息队列</tag>
        <tag>流处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015上半年软件设计师上午题部分试题分析]]></title>
    <url>%2F2016%2F11%2F09%2F2015-ruankao-am%2F</url>
    <content type="text"><![CDATA[1.计算机中cpu对其访问速度最快的是 通用寄存器&gt;CACHE&gt;内存》硬盘 2.机器字长为N位的二进制数可以用补码来表示个不同的有符号定点小数。 对正数来说，二进制的原码，反码，补码都相同。 负数的反码为符号位不变，其他位取反。 负数的补码为其反码+1 带符号的数：机器数的最高位表示符号定点数是小数点位置约定不变的数，小数点不占位置，定点数分为定点整数和定点小数定点整数（纯整数）：约定小数点的位置在机器数的最低位之后定点小数（纯小数）：约定小数点的位置在机器数的最高数值位之前（带符号数，最高数值位是在符号位之后）符号位占一位，符号位也有0 和1的变化，即出现正数和负数,8位为例：理论上有负数2^(n-1)-1 =127个、正数2^(n-1)-1=127 个再加上10000000和00000000 。共计256个。 3.cache的地址映像中，发生冲突块最小的是 1)．直接映象 每个主存地址映像到Cache中的一个指定地址的方式，称为直接映象方式。在直接映象方式下，主存中存储单元的数据只可调入Cache中的一个位置，如果主存中另一个存储单元的数据也要调入该位置则将发生冲突。地址映像的方法一般是将主存空间按Cache的尺寸分区，每区内相同的块号映像到Cache 中相同的块位置。一般地，Cache被分为2N块，主存被分为同样大小的2M块，主存与Cache中块的对应关系可用如下映像函数表示：j = i mod 2N。式中，j是Cache中的块号，i是主存中的块号。 直接映象是一种最简单的地址映像方式，它的地址变换速度快，而且不涉及其他两种映像方式中的替换策略问题。但是这种方式的块冲突概率较高，当称序往返访问两个相互冲突的块中的数据时，Cache的命中率将急剧下降，因为这时即使Cache中有其他空闲块，也因为固定的地址映像关系而无法应用。 2)．全相联映象 主存中的每一个字块可映像到Cache任何一个字块位置上，这种方式称为全相联映像。这种方式只有当Cache中的块全部装满后才会出现块冲突，所以块冲突的概率低，可达到很高的Cache命中率；但实现很复杂。当访问一个块中的数据时，块地址要与Cache块表中的所有地址标记进行比较已确定是否命中。在数据块调入时存在着一个比较复杂的替换问题，即决定将数据块调入Cache中什么位置，将Cache中那一块数据调出主存。为了达到较高的速度，全部比较和替换都要用硬件实现。 3)．组相联映象 组相联映象方式是直接映象和全相联映象的一种折衷方案。这种方法将存储空间分为若干组，各组之间是直接映像，而组内各块之间则是全相联映像。它是上述两种映像方式的一般形式，如果组的大小为1，即Cache空间分为2N组，就变为直接映像；如果组的大小为Cache整个的尺寸，就变为了全相联映像。组相联方式在判断块命中及替换算法上都要比全相联方式简单，块冲突的概率比直接映像的低，其命中率也介于直接映像和全相联映像方式之间。 参考 4.计算机中的cpu终端响应时间指的是 从发出中断请求到开始进入中断处理程序，要分清中断响应过程和中断服务过程 5.总线宽度为32bit，时钟频率为200MHZ,若总线上每5个小时周期传送一个32bit的字，则该总线的宽度为32bit*(200MHZ/5)/8bit=160MB总线的带宽指的是这条总线在单位时间内可以传输的数据总量，它等于总线位宽与工作频率的乘积。例如，对于64位、800MHz的前端总线，它的数据传输率就等于64bit×800MHz÷8(Byte)=6.4GB/s；32位、33MHz PCI总线的数据传输率就是32bit×33MHz÷8=132MB/s，等等，这项法则可以用于所有并行总线上面——看到这里，读者应该明白我们所说的总线带宽指的就是它的数据传输率。参考 6.流水线性能：采用异步并不会明显提高性能。药师加速比和效率最大化应该对流水线各级采用相同的运行时间。 7.SSH，安全套接层secure shell，建立在应用层基础上 8.9.系统安全 漏洞补丁，应用安全 数据库安全 10.11.软件产品也是作品的一种，公民拥有的为死后50年，企业为发布后50年，公民的署名权，修改权，保护作品完整权 是永远保护的个人一般只有个署名权，其他的著作权都归公司。商标谁申请谁拥有，同时申请，谁先用，谁使用。专利，谁先申请谁拥有，同时那就协商去。或者抓阄。著作权不需要申请就拥有。专利同时申请的就协商，协商不成谁也不想要。 12.13.媒体分为感觉媒体、表示媒体、表现媒体、存储媒体和传输媒体 感觉媒体感觉媒体指的是能直接作用于人们的感觉器官，从而能使人产生直接感觉的媒体。如文字、数据、声音、图形、图像等。在多媒体计算机技术中，我们所说的媒体一般指的是感觉媒体。 表示媒体表示媒体指的是为了传输感觉媒体而人为研究出来的媒体，借助于此种媒体，能有效地存储感觉媒体或将感觉媒体从一个地方传送到另一个地方。如语言编码、电报码、条形码等。 表现媒体表现媒体指的是用于通信中使电信号和感觉媒体之间产生转换用的媒体。如输入、输出设备，包括键盘、鼠标器、显示器、打印机等。 存储媒体存储媒体指的是用于存放表示媒体的媒体。如纸张、磁带、磁盘、光盘等。 传输媒体传输媒体指的用于传输某种媒体的物理媒体。如双绞线、电缆、光纤等。 14. 15.软件工程的基本要素包括方法 工具和过程 16.在概要设计阶段，选择适当的解决方案，将系统分解为若干个子系统，建立整个系统的体系结构 17.18 ，关键路径算法 你好，本题是考察项目的关键路径，关键路径：项目中时间最长的活动顺序，决定着可能的项目最短工期。本题解题时需要先生成网络图，然后找出关键路径。本题按照题干生成的图如下： 可以从图中发现ADEFH是最长的路径，也就是关键路径。由于ADF都是关键路径上的活动，对其进行修改就会影响关键路径，而B不是关键路径上的活动，对其进行缩短，经过B的所有路径的时长都不会比关键路径长，即不会影响项目工期 19.风险的优先级通常是根据 风险暴露risk exposure 来设定风险暴露又称为风险曝光度，测量的是资产的整个安全性风险，他将表示实际损失的可能性与表示大量可能损失的资讯结合到单一数字评估中，风险曝光riskexposure=错误出现率 *错误造成损失（风险损失） 20.程序设计语言中，局部变量的值是在运行时改变的 21.算法表达式对应的树，对此二叉树进行先序，中序，后序遍历，便可以得到表达式的前缀，中缀和后缀书写形式。中缀形式是算术表达式的通常形式，只是没有括号。使用后缀表达式更容易求职（在计算机中） 22.c程序中全局变量的存储空间在静态数据区分配 23.24.25记得v是增加信号量，p是减少信号量。用pv就能选出，不用是p几s几 26.访问位为0的就把他淘汰掉 27.28 嵌入式系统初始化分为片级初始化，板级初始化，系统级初始化。这是按照自底向上，从硬件到软件的次序依次进行的。片级初始化完成嵌入式微处理器的初始化，包括设置嵌入式微处理器的核心寄存器和控制寄存器。片级初始化是一个纯硬件的过程。板级初始化，同时需要设置一些数据结构和参数，同时包含软件和硬件在内的初始化过程。系统初始化，系统分区，网络系统，文件系统等，最后将控制权交给应用程序的入口 29.瀑布模型 文档驱动 系统可能不满足客户的需求快速原型模型 关注满足客户需求 可能导致系统设计差、效率低，难于维护增量模型 开发早期反馈及时，易于维护 需要开放式体系结构，可能会导致效率低下螺旋模型 风险驱动 风险分析人员需要有经验且经过充分训练 记住螺旋模型是有风险控制的就好 30.敏捷开发scrum【并列争球】：三个角色，四个会议，三个物件极限编程【xp】：交流，朴素，反馈和勇气，近螺旋式开发方法水晶方法srystal：提倡机动性方法，包含具有共性的核心元素，每个都含有独特的角色，过程模式，工作产品和实践七大体系特征：经常交付，反思改进，渗透式交流，个人安全，焦点，与专家用户建立方便的联系，配有自动测试，配置管理和经常集成功能的技术环境DSDM dynamic system development management 动态系统开发方法：以业务为核心 用户持续参与，产品经常交付，迭代增量 31.软件配置管理内容：版本控制，变更控制，过程支持 32.内聚和耦合。内聚是从功能性角度，描述的是模块内功能性的关系。耦合是各个模块之间互相连接的一种度量。耦合强弱取决于模块之间接口的复杂程度。模块之间关系越紧密，耦合性就强，独立性就差 内容耦合：一个模块直接访问另外一个模块内部数据；一个模块多个入口，这种耦合性最强。（目前高级语言不会有这种情况，最早出现在汇编）公共耦合：一组模块都访问同一个全局数据结构，公共数据环境可以是全局数据结构，共享通信区，内存的公共覆盖区等外部耦合:一组模块都访问同一全局简单变量，而且不通过参数表传递该全局变量信息，则称为外部耦合。控制耦合：模块之间传递的不是数据信息，而是控制信息，如标志，开关量等，一个模块控制了另外一个模块的功能。标记耦合：调用模块和被调用模块之间传递的数据结构而不是简单数据，同时也称作特征耦合，其实传递的是地址。 数据耦合：调用模块和被调用模块之间只是传递简单的数据项参数，相当于高级语言值传递。 非直接耦合：两个模块之间没有直接关系，他们之间的联系完全通过主模块的调用来实现的，耦合度最低，模块独立性最强。 内聚：偶然内聚，没有任何关系，逻辑内聚：调用时由传送模块参数传递时间内聚：把需要执行的动作组合在一起形成模块过程内聚：特定次数，特定关系通信内聚模块内各个组成部分都使用相同的数据结构或产生相同的数据结构顺序内聚：必须顺序执行功能内聚是最强内聚 某模块实现两个功能，向某个数据结构区域写数据和从该区域读数据，则该模块内聚类型为 通信内聚 33.正规技术评审目的（1）发现软件在功能、逻辑、实现上的错误；（2）验证软件符合它的需求规格；（3）确认软件符合预先定义的开发规范和标准；（4）保证软件在统一的模式下进行开发；（5）便于项目管理。此外，正规技术评审为新手提供软件分析、设计和实现的培训途经，后备、后续开发人员也可以通过正规技术评审熟悉他人开发的软件。 34.自顶向下集成 目的：从顶层控制（主控模块）开始，采用同设计顺序一样的思路对被测系统进行测试，来验证系统的稳定性。定义：自顶向下的集成测试就是按照系统层次结构图，以主程序模块为中心，自上而下按照深度优先或者广度优先策略，对各个模块一边组装一边进行测试。方法：① 把主控模块作为测试驱动，所有与主控模块直接相连的模块作为桩模块；② 根据集成的方式（深度优先或者广度优先），逐渐使用实际模块替换相应的下层桩模块；再用桩代替他们的直接下属模块，与已通过测试的模块或子系统组装成新的子系统。③ 在每个模块被集成时，都必须已经通过了单元测试；④ 进行回归测试（重新执行以前做过的全部或部分测试），以确定集成新模块后没有引入错误；⑤ 从上述过程中的第二步开始重复执行，直到所有模块都已经集成到系统中为止。优点：① 在测试的过程中，可以较早地验证主要的控制和判断点。② 选择深度优先组合方式，可以首先实现和验证一个完整的软件功能，可先对逻辑输入的分支进行组装和测试，检查和克服潜藏的错误和缺陷，③ 验证其功能的正确性，为此后主要分支的组装和测试提供保证；④ 能够较早的验证功能可行性，给开发者和用户带来成功的信心；⑤ 只有在个别情况下，才需要驱动程序（最多不超过一个），减少了测试驱动程序开发和维护的费用；⑥ 可以和开发设计工作一起并行执行集成测试，能够灵活的适应目标环境；⑦ 容易进行故障隔离和错误定位。 缺点：① 在测试时需要为每个模块的下层模块提供桩模块，桩模块的开发和维护费用大；② 底层组件的需求变更可能会影响到全局组件，需要修改整个系统的多个上层模块。③ 要求控制模块具有比较高的可测试性；④ 可能会导致底层模块特别是被重用的模块测试不够充分。 适用范围：① 控制结构比较清晰和稳定的应用程序；② 系统高层的模块接口变化的可能性比较小；③ 产品的低层模块接口还未定义或可能会经常因需求变更等原因被修改；④ 产品中的控制模块技术风险较大，需要尽可能提前验证；⑤ 需要尽早看到产品的系统功能行为；⑥ 在极限编程（Extreme Programming）中使用测试优先的开发方法。 自底向上集成 1) 目的：从依赖性最小的底层模块开始，按照层次结构图，逐层向上集成，验证系统的稳定性。2) 定义：自底向上集成是从系统层次结构图的最底层模块开始进行组装和集成测试的方式。3) 方法：① 从最底层的模块开始组装，组合成一个能够完成制定的软件子功能的构件；② 编制驱动程序，协调测试用例的输入与输出；③ 测试集成后的构件；④ 使用实际模块代替驱动程序，按程序结构向上组装测试后的构件；⑤ 重复上面的第二步，直到系统的最顶层模块被加入到系统中为止。4) 优点：① 即使数据流并未构成有向的非环状图，生成测试数据也没有困难。② 可以尽早的验证底层模块的行为。提高了测试效率；③ 对实际被测模块的可测试性要求要少；④ 减少了桩模块的工作量;⑤ 容易对错误进行定位。5) 缺点① 直到最后一个模块加进去之后才能看到整个系统的框架；② 只有到测试过程的后期才能发现时序问题和资源竞争问题；③ 驱动模块的设计工作量大;④ 不能被及时发现高层模块设计上的错误。6) 适用范围① 底层模块接口比较稳定的产品；② 高层模块接口变更比较频繁的产品；③ 底层模块开发和单元测试工作完成较早的产品。 自底向上的集成测试策略的优点 不需要编写桩程序，但是需要编写很多驱动模块 35.mccabe 程序控制流程图中，节点是程序代码中最小的单元。边代表节点间的控制流，一个有e条边和n个节点的流程图f。其圈复杂度为e-f+2 ，边-点+210-8+2=4 36.软件可维护性是衡量软件质量的一个重要特性，受到开发文档影响，可维护性也是软件开发阶段各个时期的关键目标，可以从可理解行，可靠性，可测试性，可行性，可移植性进行度量。 37.对象是封闭数据和行为的整体 38.面向对象程序设计选择合适的面向对象程序设计语言，将程序组织为相互协作的对象集合，每个对象表示某个类的实例，类通过继承等关系进行组织。面向对象分析：主要任务是抽取和整理用户需求并建立问题域精确模型，面向对象设计：采用协作的对象，对象的属性和方法说明软件解决方案的一种方式，强调的是定义软件对象和这些软件对象如何协作来满足要求，延续了面向对象分析。面向对象实现：采用面向对象程序设计语言下hi线系统。面向对象测试是根据规范来说明验证系统设计的正确性。 39.一个类可以通过多个重名方法而参数类型列表示不通的方法，被称为重载方法 40.41.UML关系实现关系implementation：接口和类的实现，implements 带空心三角形的虚线来表示组合关系composition：整体和部分关系，并且有统一的生存期。整体不存在，那么部分也不存在。比如头和嘴的关系。组合关系用实心菱形。整体那边是实心菱形，部分那么是箭头。 聚合关系aggregation整体和部分的关系，但是可以相互存在，就是部分可以脱离整体。比如电脑和显示器。整体那边是虚心菱形 关联关系 association 一对一，多对多，自关联等，是一种结构关系，描述了一种链。链是对象之间的连接。泛化 generation 就是继承关系，空心三角指向父类 依赖关系dependence 大多情况，依赖关系体现在某个类的方法使用另一个类的对象作为参数虚心箭头表示，开车和司机的关系 42.43uml，统一建模语言用例图：描述用户需求，从用户角度描述系统功能，椭圆为某个用户，人形为角色，帮助团队以一种可视化的方式理解系统功能需求活动图：通过动作来组织，主要描述一种方法，机制或用例的内部行为，涉及状态 活动转移分支 并发 同步静态结构图：【类图】，【对象图】，【包图】，【组合结构图】…部署图：deployment diagram 描述系统所需的硬件构件的物理部署 参考 44.45.46 组合模式，属于结构型模式，表示对象的整体，结构层次 47.某些设计模式会引入总是被用作参数的对象 visitor 访问者模式对象是一个多态accept的参数命令模式：将请求封装为一个对象，可以将不通的请求对客户进行参数化责任链模式：chain of responsibility 模式将多个对象的请求连成一条链，并沿着这条连传递该请求，直到有一个对象处理他为止，主要是避免请求的发送者和接受者之间的耦合关系。观察者模式：定义对象之间的一种一对的依赖关系，当一个对象的状态发生改变时，所有依赖他的对象都得到通知并被自动更新。 48.对高级语言源程序的编译或解释的过程可以分为多个阶段，解释方式不包括 目标代码生成。解释方式是没有目标代码生成的，与编译方式在词法，语法，语义方面大体相同，但在运行时直接执行源程序或源程序的内部形式，即解释程序不产生源程序的目标程序。这是与编译程序的主要区别。如php都是分析之后，解释成opcode码，然后解释执行，可以这么说，解释程序是参与程序的运行过程的。编译就是分开的。解释的控制器在解释程序。 参考 49. 50.递归下降分析法是一种自上而下的语法分析 51.若关系R（h,l,m,p）的主键为全码，则关系的主键为为HLMP 52. 53.遗传算法的主要基因操作是选种、交配和突变，而在进化规则、进化策略中，进化机制源于选种和突变。就适应度的角度来说遗传算法用于选择优秀的父代(优秀的父代产生优秀的子代)，而进化规则和进化策略则用于选择子代(优秀的子代才能存在)。 54.55.56 自然连接是一种特殊的等值连接，要求两个关系中进行比较的分量必须是相同的属性组，并且在结果中把重复的 属性去掉。等值连接是不会去重重复属性列的。自然连接一定是等值连接，自然连接会把重复的属性移除。 67.一个vlan【虚拟局域网】就是一个广播域。]]></content>
      <categories>
        <category>computer</category>
      </categories>
      <tags>
        <tag>软件设计师</tag>
        <tag>软考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA适配器模式-2016年上半半年考试真题]]></title>
    <url>%2F2016%2F11%2F07%2Fjava-adapter%2F</url>
    <content type="text"><![CDATA[地址信息类 要求扩展 Dutch（荷兰）语言 现采用适配器模式（adapter）实现该要求： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Address&#123; public void street()&#123;System.out.println("正常街道");&#125; public void zip()&#123;System.out.println("正常邮编");&#125; public void city()&#123;System.out.println("正常地方");&#125;&#125;class DutchAddress&#123; public void straat()&#123;System.out.println("荷兰语街道");&#125; public void postcode()&#123;System.out.println("荷兰语邮编");&#125; public void plaats()&#123;System.out.println("荷兰语地方");&#125;&#125;class DutchAddressAdapter extends DutchAddress&#123; private Address address; public DutchAddressAdapter(Address addr)&#123; this.address=addr; &#125; public void straat()&#123; this.address.street(); &#125; public void postcode()&#123; this.address.zip(); &#125; public void plaats()&#123; this.address.city(); &#125;&#125;public class Test &#123; public static void main(String[] args)&#123; Address addr=new Address(); DutchAddress addrAdapter=new DutchAddressAdapter(addr); System.out.println("\n THE DUCTH ADDRESS\n"); testDutch(addrAdapter); &#125; static void testDutch(DutchAddress addr)&#123; addr.straat(); addr.postcode(); addr.plaats(); &#125;&#125; 类图]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>软件设计师</tag>
        <tag>JAVA</tag>
        <tag>适配器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA策略模式-2015年下半年考试真题]]></title>
    <url>%2F2016%2F11%2F07%2Fjava-strategy%2F</url>
    <content type="text"><![CDATA[大型商场要求商店有三种策略[原价、打折、满减] 现采用策略模式（strategy）实现该要求： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//枚举三种策略enum TYPE &#123;NORMAL,CASH_DISCOUNT,CASH_RETURN&#125;interface CashSuper&#123; public double acceptCash(double money);&#125;//原价class CashNormal implements CashSuper&#123; public double acceptCash(double money)&#123; return money; &#125;&#125;//打折class CashDiscount implements CashSuper&#123; private double discountRate; public CashDiscount(double discountRate)&#123; this.discountRate=discountRate; &#125; public double acceptCash(double money)&#123; return money*discountRate; &#125;&#125;//满减class CashReturn implements CashSuper&#123; private double moneyCondition; private double moneyReturn; public CashReturn(double moneyCondition,double moneyReturn)&#123; this.moneyCondition=moneyCondition; this.moneyReturn=moneyReturn; &#125; public double acceptCash(double money)&#123; double result =money; if(money&gt;=moneyCondition)&#123; result=money-moneyReturn; &#125; return result; &#125;&#125;// 策略public class CashContent &#123; private CashSuper sc; private TYPE t; public CashContent (TYPE t)&#123; switch (t)&#123; case NORMAL: sc=new CashNormal(); break; case CASH_DISCOUNT: sc=new CashDiscount(0.9); break; case CASH_RETURN: sc=new CashReturn(300.00,50.00); break; &#125; &#125;//实现 public static void main(String[] argus)&#123; CashContent cc=new CashContent(TYPE.CASH_RETURN); //CashContent cc=new CashContent(TYPE.CASH_DISCOUNT); //CashContent cc=new CashContent(TYPE.NORMAL); System.out.println(cc.sc.acceptCash(900));//结果为900-50=850.0 &#125;&#125; 类图]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>软件设计师</tag>
        <tag>JAVA</tag>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬盘中磁道、扇区基本概念]]></title>
    <url>%2F2016%2F11%2F05%2Fdisk-basic%2F</url>
    <content type="text"><![CDATA[用AIDA64 Extreme工具看下我的low硬盘 柱面磁头扇区磁道？ WTF? 一图胜千言 在看个二合一版的图 温习下英语 磁头（head） 磁道就是一个圈（track） 柱面就是多个磁道号相同的圈组成的（cylinder） 扇区（sector） 圆盘（platter） 再回到我的low硬盘 存储容量 ＝ 磁头数 × 磁道(柱面)数 × 每道扇区数 × 每扇区字节数 248085*63*16*512/1000/1000 = 128 035.67616M 注意512是Byte 简单说一下 磁盘由N个盘片构成，每个盘片一般有两面，一面一个磁头，两面都可以存储数据 磁道号相同的组成一个柱面，柱面是我们硬盘分区时候最小单位。 sector 扇区 磁道按512Byte分成若干扇区，计算机对硬盘读写，是按扇区为最小单位。 而一般文件系统中的BLOCK为KB，通常为4KB.（现在有的硬盘每个扇区有4K了） 可以这么说：即使读一个字节，也必须把这512字节全部读入内存 在linux上看一把硬盘root@lyh:~# fdisk -l Disk /dev/xvda: 42.9 GB, 42949672960 bytes 255 heads, 63 sectors/track, 5221 cylinders, total 83886080 sectors 硬盘容量就是 heads*sectors*cylinders*512=255*63*5221*512/1000/1000/1000 = 42.94418688G]]></content>
      <categories>
        <category>computer</category>
      </categories>
      <tags>
        <tag>硬盘</tag>
        <tag>扇区</tag>
        <tag>磁道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大端字节序与小端字节序]]></title>
    <url>%2F2016%2F11%2F04%2Fbig_small_binary%2F</url>
    <content type="text"><![CDATA[大端字节序：数据的低位字节保存在内存的高地址端，等于内存的低位保存的是数据的高位地址小端字节序：数据的高位字节保存在内存的高地址端，网络字节序：tcpip是基于大端字节序 缘由：内存每个地址单元对应一个字节，就是8bit。现在为32或者64位cpu，寄存器的宽度在大于了一个字节之后，字节排放就需要有个顺序，就有了大端和小端。所以大端和小端指的是寄存器的排列顺序。所以只是在跨平台或者网络编程程序中会经常用到，一般情况不会用到。 在c语言中，指针大小在32位机器上为4字节8bit，64位机器上为8字节8bit ———————– 最高内存地址 0xffffffff栈底栈 栈顶NULL (空洞)堆未初始 化的数据———————– 统称数据段 初始化的数据正 文段(代码段)———————– 最低内存地址 0x00000000 内存低地址存数据的高位，内存的高地址存数据的低位。内存是由低到高增长，按照单个进程内的存储器地址由低到高分别为 代码段 数据段（全局变量+静态变量） 堆（动态分配内存） 栈（局部变量） 如何验证本机是低位还是高位？不同的处理器有不同的大小端模式 本地a字节序转成网络字节序-发送给b b接收网络字节序 -b转成本地字节序 ，网络字节序为大端模式 比如内存地址由低到高：0x01 0x02数据为12345678，数据的1234为高位，5678为低位。 0x01存的是1234，内存低地址存数据高位，为大端。 12345678910111213141516171819#include &lt;stdio.h&gt;int main()&#123; int num=0x12345678; char *pnum = (char *)&amp;num; printf(" sizeof pnum is %i\n",sizeof(pnum)); printf("first %p,value is %x\n",pnum,pnum[0]); printf("second %p,value is %x\n",pnum+1,pnum[1]); printf("third %p,value is %x\n",pnum+2,pnum[2]); printf("fourth %p,value is %x\n",pnum+3,pnum[3]);&#125; 执行结果，可以看出，78存在了低地址位，所以是小端序。 ·123456sizeof pnum is 4first 1703740,value is 78second 1703741,value is 56third 1703742,value is 34fourth 1703743,value is 12Press any key to continue 结合php的PACK/unpack，可以得出一致结果:小端序 12345678910111213&lt;?phpdefine(&apos;BIG_ENDIAN&apos;, pack(&apos;L&apos;, 1) === pack(&apos;N&apos;, 1));if (BIG_ENDIAN)&#123; echo &quot;大端序&quot;;&#125;else&#123; echo &quot;小端序&quot;;&#125;]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>大端字节序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的插入排序]]></title>
    <url>%2F2016%2F11%2F04%2Fphp-insert-sort%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940&lt;?php/*1.外层循环是从数组中选出一个arr[i]将要插入到有序数组的数2.内层循环是遍历已经排序好的数组，将arr[i]（也就是temp）依次与有序数组做对比，如果发现有序数组其中一个比准备插进来的arr[i]大，那么谁比这个arr[i]大，谁就出去，把位置腾出去，当然比arr[i]大的这个数也不能扔，就给他放在已经排号序数组中且相对于他的下一个索引就好了。3.2还有个空档，这时候把temp补上就行了*/$arr = [3, 7, 6,8,1];function insertSort($arr)&#123; for ($i = 1; $i &lt; count($arr); $i++) &#123; echo '外层&#123;$i&#125;=' . $i . "次循环" . "\n"; $temp = $arr[$i];//待插入的数 echo '外层待插入的数为&#123;$temp&#125;=' . $temp . "\n"; for ($j = $i - 1; $j &gt;= 0 &amp;&amp; $temp &gt; $arr[$j]; $j--) &#123; echo '====&gt;内层&#123;$j&#125;=' . $j . "次循环" . "\n"; echo '要插入的$temp' . "=$temp " . "VS " . '已经排序好的$arr[$j]=' . "$arr[$j]" . "小\n"; $arr[$j + 1] = $arr[$j]; echo '所以要腾出一个空来给temp,这时候索引$j的值为'.$arr[$j].'要往后靠，此时$j=' . $j, "\n"; &#125; echo '外层&#123;$i&#125;=' . $i . '次循环结束'; // var_dump($temp,$arr[$i]);注意此处两值如果已经经历了内层循环，那么就！== $arr[$j + 1] = $temp; echo ' 此时完成$j=' . $j . '把temp的值' . "$temp" . '赋予$j+1' . "\n"; echo "=====", "\n"; &#125; return $arr;&#125;var_dump(insertSort($arr));]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>插入排序</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[此博客的'构造方法']]></title>
    <url>%2F2016%2F11%2F04%2Fpost%2F</url>
    <content type="text"><![CDATA[其实这就是熟悉熟悉怎么用git，不建议一个仓库弄两个分支… HEXO初始化暂设当前目录 iamtb，且github仓库A放hexo dynamic文件，仓库B放hexo static文件 npm install -g hexo npm install hexo-deployer-git --save hexo init iamtb 在iamtb文件夹下 hexo s 来个NB的NEXT主题在iamtb目录下载主题NEXT， git clone https://github.com/iissnan/hexo-theme-next themes/next 修改基本主题配置，包括语言，page等，确保本地预览无误。 [重点来了！！！][重点来了！]必须删除下载主题内的.git目录，否则主题无法上传到A库，因为你自己下载的主题文件有.git控制文件夹。另外一定修改.gitignore ,把其中的node_modules和db.json，不要ignore，不要ignore，不要ignore。 意思就是你的.ignore文件是这样： .DS_Store Thumbs.db *.log public/ .deploy*/ 推到A仓库在github新建A仓库，把目前的这些文件都推到A库。参考以下命令 503 git status 504 git init 505 git status 506 git add * 507 git commit -m &apos;init hexo and next theme&apos; 508 git status 509 git remote 510 git remote add origin https://github.com/tuber/tbhexo.git 511 git branch 512 git push 513 git push origin master 建立yourname.github.iogithub建立仓库B,建完后可一进入仓库setting进行初始化（Launch automatic page generator），保证访问yourname.github.io正常访问。 本地config配置 目的就是执行hexo d的时候推到B仓库 deploy: type: git repo: https://github.com/tuber/tuber.github.io.git branch: master message: just static 本地发布测试文章 如果网络慢可以在主题设置中禁用google字体 hexo new ‘001’ hexo new ‘002’ hexo new ‘003’ hexo g git commit -am&apos;add 3 post&apos; git push origin master #把本地master推到远程origin，此处为A仓库 hexo d #把生成静态文件推到B仓库 完成80%了，如果换电脑了呢？ 那我们由于之前都做好了准备，我们只需要在你需要的地方 git clone https://github.com/tuber/tbhexo.git， 这样你目录下就会新增了一个tbhexo文件夹 进入thhexo目录，不用init 不用init 不用init npm install hexo npm install hexo-deployer-git 然后还是先hexo s 启动一下，正常没问题 然后从tbhexo文件夹下，（就相当于你另外一台电脑了）随便创建几个文件： hexo new add tbhexo 004 hexo new add tbhexo 005 hexo new add tbhexo 006 可以参考以下命令 504 git status 505 git add * 506 git commit -m&apos;add 3 posts and tow helloword posts in tbhexo&apos; 507 git push origin master 最后一步hexo d 完工。这样你在另外一台电脑上更新的文章也推到yourname.github.io上了。 如此循环只需要 git pull origin master更新 git push origin master 上传即可。 大问题：目测他有一个默认文章hello word ，理论应该在第一个文章，但是经过此番折腾他跑到第三文章了。贴图： PostScript：备忘录 第一步：应该先git pull origin master ，[git branch git remore查看]从远程拉一下分支到本地，保持同步。 第二步：hexo new yourpost，在本地文件夹下source/编辑yourpost.md 本地预览，然后，hexo g 生成对应文件如tags img等，确认格式文件无误，然后增加、提交git add *，git status，查看对应文件是否被捕捉完整 提交到本地 git commit -m &#39;add yourpost&#39; 提交到远程分支(这个分支是为了更换电脑后，文章等都没了的问题)，git push origin master 发布到你的对应io上，我的就是tuber.github.io.这个是配置文件配的。注意与5的区别]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>github.page</tag>
        <tag>hexo</tag>
        <tag>git</tag>
        <tag>node</tag>
      </tags>
  </entry>
</search>
